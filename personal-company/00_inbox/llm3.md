感觉大约模型有点类似于分布式系统的最终一致性。 它丢掉了一些确定性,而换来了更多的东西。 我们会容忍有一定的误差,在应用层上有一定的误差。 但我们希望它的影响力,影响面尽可能的小,我们有办法补救。 然后通过其他方式去校正,这样的话有很大程度去提高这个效率。 这是一种应用层的使用。 这个效率,它的本质是什么? 吞吐率。 先从宏观来说,它对我们人脑的好处。 我们人脑一天能处理多少个事情,以前是X-level量级的事情, 但是后来可能X的平方,10的X,20的X等等这些, 它可以把我们大脑能处理的事情进行一个吞吐率的增加, 也就是说增加我们大脑的效率。 它们本质是同一类问题,你要理解最终一致性, 把它引入到认知和决策的层面。 最终一致性是什么意思? 它要做数据复制,它要做缓存,它要做消息系统,它要做状态同步。 现在它第一次进入了理解、推断、判断、行动建议。 以前只是做一下数据和状态层面的一个同步, 但现在它可能做的事情更多了, 它做的事情更多就意味着它更危险,这是肯定的。 它开始帮我们做决策,它甚至开始自主做决策。 对于一个分布式系统,不严格要求它的最终一致性, 它的前提是什么? 它影响力有限,它能回滚,能重视,能有最终收敛的一个机制。 它的核心不是允许错误,它的核心是它的错误是暂时的, 可观测可纠正的,这个很重要, 这个就是我们要对大型模型做的事情。 大型模型在硬盘上面我们希望什么呢? 它能被兜底,它能被校正,它能收敛, 它能错了不产生,它的影响力、影响面有限, 这些都是最终一致性的前提条件。 不是说它不能出错,而是说它出错的地方我们能够接受, 这个是核心, 所以我们希望它能够在最终正确性的机制的地方使用。 这就是大型模型, 应该被使用在工程或者世界上的地方。 在分布式系统上它是数据一致性, 但在大型模型上面它是认知的一致性。 从各个角度,大型模型在哪些方面, 它的黄金区是它擅长的地方。 很大的误解是什么? 就是大型模型在我们工程上最适合的地方不是自动执行。 有些人经常想,我们利用AI去自动跑, 部署自动跑测试,自动跑whatever, 很多东西,但它最大的价值不是自动做这些事情, 它是降低人类的认知品质, 本身它是提高人脑的吞吐率。 以前你一天写几个函数一天就到头了, 现在一个函数可能半分钟就给你写完, 并且能够完成了, 它本身就是一个仕途, 它帮你写一个脚本能够完成你当前的一个工作, 这就是一个仕途,而不是一个事实层, 要分清这个东西。 它最核心的东西是它能够提升系统的整体吞吐量, 就是提高效率, 但是风险仍然是人类承担的, 所以人类做的是什么呢? 就是作为这个认知的最终一致性, 要把控这个认知的最终一致性,认知, 这个字。
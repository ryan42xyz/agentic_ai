# 原创性
大语言模型的本质是什么? 是一个不稳定的概率生成器 本质上就是一个概率的生成器 也就是说我生成一些文字 比如说我生成苹,苹果的苹 它很容易它就生成果 这就是一种概率 因为这个全世界有大量的人去说这件事情 说这个词 所以它产生了一个概率 它的概率是基本上整个互联网上的 是整个互联网上的吗? 这里要有个to do 基本是在预测下一个字 所以当你规划一个需求之后 它会给你预测这个会怎么写 因为前人已经写了大量的需求之后 其实这个就很好写了 但它仍然是什么呢? 它是个概率 所以当你想要一个绝对的东西的时候 它经常会做的不太好 就你想要绝对的东西 尤其是在infra上面 它就是会搞不好 你如论如何怎么加强这个大叶模式 它仍然是一个概率生成器 只是它生成的可能更加能够读懂你的想法 更加清晰 但是它是结构性的缺陷 所以当你要summary一个page的时候 它为什么会有问题? 本质上就是它会丢失信息 它丢失信息 第一它丢失信息 因为它压缩了信息 第二它可能因为概率生成 导致它无端的联想一些信息 可能和你这个page上的information不太相关 当然也相关 但不是你这个information上的东西 它是基于语调统计的 它是一次不可逆的信息坍缩 也就是说当你ps了一个图片之后 你再想把它完全p回去 你除了follow一个pattern 比如说1加1等于2 然后你知道它是加了1 你这个2减1才能回去 但如果你不知道 其实你很难知道它以前的x是什么东西 它有几个不稳定的来源 从原理上面 本质上就是采样的不确定 上下文的脆弱 没有全局一致性 当很简单的 当你去找下一批聊天的时候 你会不断的被引导 或者你自己引导这个对话的样子 它很容易就走偏 也就是说它和你刚开始第一次说的话 说的topic不太一样了 这是经常会遇到的事情 还有就是长期记忆和版本的问题 它基本长期记忆不太好 我们可能会加一些持久化存储 cache等等这些东西 作为它长期记忆 然后去搜索 也就是IG 但本质上它这个大眼模型本身 它不是一个长期记忆的一个东西 所以作为AI Infra 我们需要将这个非常灵活的 但是不太稳定的东西 想把它放到一个灵活 不需要那么灵活 需要一点点灵活 但是要比较稳定的一个东西 因为很显然 Infra 当你在生产环境做一些操作的时候 你肯定不希望它去太过分的做一些事情 而导致你整个生产环境的不稳定 最终导致业务出现问题 一个改变策略的方式 就是把大语言模型放到你系统中的一环 而不是将它放到上帝的位置 去控制你的每一环的行为 也就是A比C 它可能是其中的B和其中的D 但它不能是一个全局的一个东西 然后去操纵你的A比C 你能理解这个意思吗 实际上可以将它看成一个函数 它的函数有一些input, prompt, context, seed 然后它会生成一个output 所以为什么说prompt不是主要的一个东西 不是说不是主要 它不是唯一我们需要去关心 当我们使用大语言模型的时候的东西 这个函数非常重要 叫output等于function括号 input, prompt, context, seed括号 我们希望它在局部有创造力就可以了 限制在局部
在工廠上的核心原則就是,它既然不可控碼,但它又能擴展我們人類的一些思維。 那它最好的辦法就是做一個拍聲類,有點像那個視圖,就是我們任何的RAW input不要丟棄,任何時候都不要丟棄。 你只要把它當成一個可以回放的話,你人類的input一定是要留著的。 然後我們就說這裡有五條原則,第一個就是永遠保存這個RAW input,任何時候都保存這個RAW input, 然後它只做拍聲類,不覆蓋事實的層。 然後同時Summary,你任何時候做Summary的話,它肯定只是視圖嘛。 视图就是我们任何的Raw Input 它既然不可控嘛,但它又能扩展我们人类的一些思维 那它最好的办法就是做一个派生类嘛,有点像那个视图 就是我们任何的Raw Input不要丢弃,随任何时候都不要丢弃 然后你只要把它当成一个可以回放的嘛 可以回放的话,你人类的Input一定是要留着的 然后我们就说这里有五条原则 第一个就是永远保存这个Raw Input 任何时候都保存这个Raw Input 然后它只做派生类不覆盖事实的层 然后同时Summary,你任何时候做Summary的话 它肯定只是视图嘛 任何时候这个Summary都是视图 它不是存储,它是生成的 然后你可以做缓存,但它一定是可以丢弃的 然后多结果大于单结果的意思就是 我们利用概率去做这件事情 能把它更好的把它保存下来 然后还有一个就是把它放到中间 就作为系统的一部分 而不是中心 就是应该是输入LIM 然后人,然后规则再处理 而不是输入LIM存档 你存档之后其实一方面是 你如果把它当成终点的话 其实你根本没有把它记在你脑子里面 其实你完全没有对你的大脑进行一个复利 它只是生成了一次视图 它可能生产大量的视图 而你都无从瞎眼去读它 对你个人或者对任何人的本身 它的意义其实不大 所以回过头来 我们说这个东西就是 一个是你要假设它是错的 那你就要用概率 就要用多次加概率这个东西来 更快更强大的避免 当然这是要设计一个好的代用模型 而另一方面就是说 你把它当视图 你把它生成的东西 当做一个派生的东西 而不是系统本身 所以这意味着你要留着这个role input 然后第三个就是说 你把它当成这个系统的一部分 让它去做它合适做的事情 而不是让它做所有的事情 它适合的东西 它不适合所有东西 它适合某些东西 你不能让它去做所有东西 它很容易就自我发挥
第三,大爺模型是一個概率生成器,還不夠工程化的話,是一個高危條件分佈的監視器,也就是說在一個極高危的相連空間,這我完全聽不懂。 他的危險不來自於幻覺,來自於他可能一本正經的胡說八道,這是最見鬼的。 不管你寫什麼東西,他一本正經的胡說八道,你如果無法去驗證他的事實,那他將是一個很危險的東西,就是一個不懂裝懂的比一個不懂的在一個重要的崗位上,那他一定會產生的危害是更重要的,因為你不知道他可能什麼時候發生問題。 他可能九十九是沒有問題,但最後可能有一百第一百次會有問題。 我們怎麼馴化這個東西呢?讓他為我們所用呢?讓他為我們做更大層面的事情呢? 首先把他放在一個他既然很很靈活,那你一定要把他限制嗎?你給他指出起點和終點,他可能隨便走,但他只要幫你走到,而且中間隨便走,他不產生問題就可以了嗎? 比如說讓你訂一個自行車走的,你不能讓他去走高速嗎?他把你引到高速路上,那肯定是不行的嗎?這是大圓模型的結果性問題,你沒辦法改變他,你也不需要改變他,你應該知道他的局限而利用他,更好的利用他,更高效的利用他。 這裡有個核心的就是我們之前提到的,就是如果他不可驗證,不可重複,不可逆,那他就是一個仕途,他不是事實。 戰勝他的武器,不是控制他,你怎麼控制他都很難的,那怎麼辦呢?統計嗎? 在工程上,他如果生成代碼有問題,他可能生成一直有問題,那你讓他跑嗎?跑了再利用那個測試用力去給他規範嗎? 一方面就是單次肯定比多次差,我多次利用他然後去生成一些一致的主題,反復被提到的問題,然後重複出現的結構等等這些東西,他本身上我們是用概率去對抗這個不穩定性,你不能說一個藥他有99%的作用,他可能在某些人身上產生副作用,你不能說他是好的,完全好的,也不能說他是完全壞的。 你只能透過概率去搞這件事情,把概率盡量提高。 所以我們怎麼利用這個大型模型呢?首先我們的role我們要保留嘛,然後我們盡量分類擴展嘛,然後做信息壓縮是很晚才做的,為什麼要很晚?因為一旦做信息壓縮你就回不去了。 信息壓縮是什麼呢?就是大型模型經常出現的地方summary,還有對於一個外行人,但是有一定工程基礎的人,一定聽過NLP,這是一個文本處理的一個機械學方法,他可能有一些深度學習,但是另一方面,如果我們已經有了大型模型之後,我們還需要NLP嗎?他們是在……
感觉大约模型有点类似于分布式系统的最终一致性。 它丢掉了一些确定性,而换来了更多的东西。 我们会容忍有一定的误差,在应用层上有一定的误差。 但我们希望它的影响力,影响面尽可能的小,我们有办法补救。 然后通过其他方式去校正,这样的话有很大程度去提高这个效率。 这是一种应用层的使用。 这个效率,它的本质是什么? 吞吐率。 先从宏观来说,它对我们人脑的好处。 我们人脑一天能处理多少个事情,以前是X-level量级的事情, 但是后来可能X的平方,10的X,20的X等等这些, 它可以把我们大脑能处理的事情进行一个吞吐率的增加, 也就是说增加我们大脑的效率。 它们本质是同一类问题,你要理解最终一致性, 把它引入到认知和决策的层面。 最终一致性是什么意思? 它要做数据复制,它要做缓存,它要做消息系统,它要做状态同步。 现在它第一次进入了理解、推断、判断、行动建议。 以前只是做一下数据和状态层面的一个同步, 但现在它可能做的事情更多了, 它做的事情更多就意味着它更危险,这是肯定的。 它开始帮我们做决策,它甚至开始自主做决策。 对于一个分布式系统,不严格要求它的最终一致性, 它的前提是什么? 它影响力有限,它能回滚,能重视,能有最终收敛的一个机制。 它的核心不是允许错误,它的核心是它的错误是暂时的, 可观测可纠正的,这个很重要, 这个就是我们要对大型模型做的事情。 大型模型在硬盘上面我们希望什么呢? 它能被兜底,它能被校正,它能收敛, 它能错了不产生,它的影响力、影响面有限, 这些都是最终一致性的前提条件。 不是说它不能出错,而是说它出错的地方我们能够接受, 这个是核心, 所以我们希望它能够在最终正确性的机制的地方使用。 这就是大型模型, 应该被使用在工程或者世界上的地方。 在分布式系统上它是数据一致性, 但在大型模型上面它是认知的一致性。 从各个角度,大型模型在哪些方面, 它的黄金区是它擅长的地方。 很大的误解是什么? 就是大型模型在我们工程上最适合的地方不是自动执行。 有些人经常想,我们利用AI去自动跑, 部署自动跑测试,自动跑whatever, 很多东西,但它最大的价值不是自动做这些事情, 它是降低人类的认知品质, 本身它是提高人脑的吞吐率。 以前你一天写几个函数一天就到头了, 现在一个函数可能半分钟就给你写完, 并且能够完成了, 它本身就是一个仕途, 它帮你写一个脚本能够完成你当前的一个工作, 这就是一个仕途,而不是一个事实层, 要分清这个东西。 它最核心的东西是它能够提升系统的整体吞吐量, 就是提高效率, 但是风险仍然是人类承担的, 所以人类做的是什么呢? 就是作为这个认知的最终一致性, 要把控这个认知的最终一致性,认知, 这个字。
我们开始深入的分析,从英法视角深入的分析, Agentic AI能够做哪些事情,从你具体的场景, 第一个就是Encore,叫Incident Response,Incident Response, 它的一个大概的一个过程是什么,来了一些消息, 可能是杂乱的,可能是拼装的,可能是很多东西, 一个以前你需要人脑去做处理,去做上下文搜索, 这个部分是对类的,定位这个事情是对类的, 然后AI能给你做理解,能给你把信息压缩, 能给你做一个即时的推理,比如说以前它影响面, 你需要推它的影响面,大概会影响到多少客户, 影响到多少个集群,你现在做AI的话, 它可以给你做一些即时的推理, 但是它需要一些上下文,它需要知道你, 比如说你系统的架构是怎么样的, 你们公司,你们地方这个架构是怎么样的, 跟应的候选,就是假设,跟应就是这个Root和Course分析, 最后就是做行动决策,你去get, Kubernetes get一个什么Post Status, 甚至去add一个deployment的replica等等这些东西, 那这个是高风险的,你如果把这个给Agentic AI, 那可能它就会帮你把系统搞出很多问题, 所以为什么我们之前说要把它放到安全的地方, 第二,常见就是我们经常会去deploy, scale和add一些config map等等这些东西, 它说的是在Kubernetes的场景上面, 那你把这些东西交给Agentic AI, 你放心吗,反正我不放心, 它这个问题就是什么呢, 它的影响面非常的大, 比如说我们说的是爆炸半径非常大, 它的回滚成本还比较高, 当你改了一个东西的时候, 它可能影响很多东西, 影响回滚它是非常麻烦的, 然后它可能有很多的依赖, 依赖它这个AI可能不知道, 可能是你们公司在日积月累的过程中形成的一个历史包袱, 然后这个责任你既然跑了这个AI, 那责任肯定是你的,肯定不是AI的, 第三个场景就是Agent的执行, Agent这个东西它很容易, 很多人很容易把它想成叫做autonomous, automous是自动化, 它看起来是自动化, 但它最核心的, 最本质的地方不是做自动化, 它是做ultra straight, 最好的就是以身认知的吞吐, 所以就是AI辅助SRE, SRE的评级是哪一项, 给你们的操作,操作是最后一步, 在操作之前它有很多东西, 什么上下文啊,模式记忆啊, 历史的对比啊, 心智负载啊,等等这些东西, 然后AI里面什么呢, 能够在从历史中的instance中进行对比啊, 加速的开始和减速啊, 以经验总结啊, 总结而出的采取啊, 新人加速的一些系统啊, 等等这些东西, 我们开始深入的分析, 从英法的视角深入的分析, 从你具体的场景, 第一个就是商货啊, 叫做instant response, instant response它的一个大概的过程是什么, 来了一些消息, 可能是杂乱的, 可能是冰装的, 可能是很多东西, 你一个以前你需要人脑去做数据, 去做上下文的搜索, 这个部分是最累的, 就定位这个事情是最累的, 然后AI里面什么呢, AI能给你做理解, 能给你把信息做压缩, 能给你做一个近似的推理, 比如说以前它影响面, 你需要推它的影响面, 影响面大概会影响到多少客户, 多少个集群, 你现在做AI的话, 它可以给你做一些近似推理, 但它需要一些上下文, 它需要知道你系统的架构是怎么样的, 你大概怎么, 你们公司, 你们地盘这个架构是怎么样的, 跟应的候选, 就是假设, 跟应就是这个root和course分析, 最后就是做行动决策, 你去get, Kubernetesget一个什么border status, 甚至你去add一个deployment的replica, 等等这些东西, 那这个是高风险的, 你如果把这个给Agenic AI, 那可能它就会帮你把系统搞出很多问题, 所以为什么我们之前说要把它放到安全的地方, 第二, 我们经常会去deploy, scale和add, 一些config map, 等等这些东西, 说的是在Kubernetes的场景下, 那你把这些东西交给Agenic AI, 你放心吗, 反正我不放心, 是吧, 它这个问题就是什么呢, 它的影响面非常的大, 比如说我们说的是爆炸半径非常大, 它的回滚成本还比较高, 当你改了一个东西的时候, 它可能影响很多东西, 你想回滚它是非常麻烦的, 然后它可能有很多的依赖, 依赖它这个AI可能不知道, 形成了一个历史包袱, 然后这个责任, 你既然跑了这个AI, 那责任肯定是你的, 肯定不是AI的, 第三个场景就是Agenic的执行, Agenic这个东西它很容易, 很多人很容易把它想成到做autonomous, automous, 就是自动化, 它看起来是自动化, 但它最核心的, 最本质的地方不是说自动化, 而是说ultra straight, 最好的就是理论认知的吞吐, 或者是AI辅助SRE, SRE的评级程度下, 给你们操作, 操作是最后一步, 在操作之前, 上下文, 模式记忆, 历史的对比, 心智负载, 然后从历史中对比, 简述, 经验总结, 新人家族理解系统, 等等这些东西。
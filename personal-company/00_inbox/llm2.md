我们开始深入的分析,从英法视角深入的分析, Agentic AI能够做哪些事情,从你具体的场景, 第一个就是Encore,叫Incident Response,Incident Response, 它的一个大概的一个过程是什么,来了一些消息, 可能是杂乱的,可能是拼装的,可能是很多东西, 一个以前你需要人脑去做处理,去做上下文搜索, 这个部分是对类的,定位这个事情是对类的, 然后AI能给你做理解,能给你把信息压缩, 能给你做一个即时的推理,比如说以前它影响面, 你需要推它的影响面,大概会影响到多少客户, 影响到多少个集群,你现在做AI的话, 它可以给你做一些即时的推理, 但是它需要一些上下文,它需要知道你, 比如说你系统的架构是怎么样的, 你们公司,你们地方这个架构是怎么样的, 跟应的候选,就是假设,跟应就是这个Root和Course分析, 最后就是做行动决策,你去get, Kubernetes get一个什么Post Status, 甚至去add一个deployment的replica等等这些东西, 那这个是高风险的,你如果把这个给Agentic AI, 那可能它就会帮你把系统搞出很多问题, 所以为什么我们之前说要把它放到安全的地方, 第二,常见就是我们经常会去deploy, scale和add一些config map等等这些东西, 它说的是在Kubernetes的场景上面, 那你把这些东西交给Agentic AI, 你放心吗,反正我不放心, 它这个问题就是什么呢, 它的影响面非常的大, 比如说我们说的是爆炸半径非常大, 它的回滚成本还比较高, 当你改了一个东西的时候, 它可能影响很多东西, 影响回滚它是非常麻烦的, 然后它可能有很多的依赖, 依赖它这个AI可能不知道, 可能是你们公司在日积月累的过程中形成的一个历史包袱, 然后这个责任你既然跑了这个AI, 那责任肯定是你的,肯定不是AI的, 第三个场景就是Agent的执行, Agent这个东西它很容易, 很多人很容易把它想成叫做autonomous, automous是自动化, 它看起来是自动化, 但它最核心的, 最本质的地方不是做自动化, 它是做ultra straight, 最好的就是以身认知的吞吐, 所以就是AI辅助SRE, SRE的评级是哪一项, 给你们的操作,操作是最后一步, 在操作之前它有很多东西, 什么上下文啊,模式记忆啊, 历史的对比啊, 心智负载啊,等等这些东西, 然后AI里面什么呢, 能够在从历史中的instance中进行对比啊, 加速的开始和减速啊, 以经验总结啊, 总结而出的采取啊, 新人加速的一些系统啊, 等等这些东西, 我们开始深入的分析, 从英法的视角深入的分析, 从你具体的场景, 第一个就是商货啊, 叫做instant response, instant response它的一个大概的过程是什么, 来了一些消息, 可能是杂乱的, 可能是冰装的, 可能是很多东西, 你一个以前你需要人脑去做数据, 去做上下文的搜索, 这个部分是最累的, 就定位这个事情是最累的, 然后AI里面什么呢, AI能给你做理解, 能给你把信息做压缩, 能给你做一个近似的推理, 比如说以前它影响面, 你需要推它的影响面, 影响面大概会影响到多少客户, 多少个集群, 你现在做AI的话, 它可以给你做一些近似推理, 但它需要一些上下文, 它需要知道你系统的架构是怎么样的, 你大概怎么, 你们公司, 你们地盘这个架构是怎么样的, 跟应的候选, 就是假设, 跟应就是这个root和course分析, 最后就是做行动决策, 你去get, Kubernetesget一个什么border status, 甚至你去add一个deployment的replica, 等等这些东西, 那这个是高风险的, 你如果把这个给Agenic AI, 那可能它就会帮你把系统搞出很多问题, 所以为什么我们之前说要把它放到安全的地方, 第二, 我们经常会去deploy, scale和add, 一些config map, 等等这些东西, 说的是在Kubernetes的场景下, 那你把这些东西交给Agenic AI, 你放心吗, 反正我不放心, 是吧, 它这个问题就是什么呢, 它的影响面非常的大, 比如说我们说的是爆炸半径非常大, 它的回滚成本还比较高, 当你改了一个东西的时候, 它可能影响很多东西, 你想回滚它是非常麻烦的, 然后它可能有很多的依赖, 依赖它这个AI可能不知道, 形成了一个历史包袱, 然后这个责任, 你既然跑了这个AI, 那责任肯定是你的, 肯定不是AI的, 第三个场景就是Agenic的执行, Agenic这个东西它很容易, 很多人很容易把它想成到做autonomous, automous, 就是自动化, 它看起来是自动化, 但它最核心的, 最本质的地方不是说自动化, 而是说ultra straight, 最好的就是理论认知的吞吐, 或者是AI辅助SRE, SRE的评级程度下, 给你们操作, 操作是最后一步, 在操作之前, 上下文, 模式记忆, 历史的对比, 心智负载, 然后从历史中对比, 简述, 经验总结, 新人家族理解系统, 等等这些东西。
第三,大爺模型是一個概率生成器,還不夠工程化的話,是一個高危條件分佈的監視器,也就是說在一個極高危的相連空間,這我完全聽不懂。 他的危險不來自於幻覺,來自於他可能一本正經的胡說八道,這是最見鬼的。 不管你寫什麼東西,他一本正經的胡說八道,你如果無法去驗證他的事實,那他將是一個很危險的東西,就是一個不懂裝懂的比一個不懂的在一個重要的崗位上,那他一定會產生的危害是更重要的,因為你不知道他可能什麼時候發生問題。 他可能九十九是沒有問題,但最後可能有一百第一百次會有問題。 我們怎麼馴化這個東西呢?讓他為我們所用呢?讓他為我們做更大層面的事情呢? 首先把他放在一個他既然很很靈活,那你一定要把他限制嗎?你給他指出起點和終點,他可能隨便走,但他只要幫你走到,而且中間隨便走,他不產生問題就可以了嗎? 比如說讓你訂一個自行車走的,你不能讓他去走高速嗎?他把你引到高速路上,那肯定是不行的嗎?這是大圓模型的結果性問題,你沒辦法改變他,你也不需要改變他,你應該知道他的局限而利用他,更好的利用他,更高效的利用他。 這裡有個核心的就是我們之前提到的,就是如果他不可驗證,不可重複,不可逆,那他就是一個仕途,他不是事實。 戰勝他的武器,不是控制他,你怎麼控制他都很難的,那怎麼辦呢?統計嗎? 在工程上,他如果生成代碼有問題,他可能生成一直有問題,那你讓他跑嗎?跑了再利用那個測試用力去給他規範嗎? 一方面就是單次肯定比多次差,我多次利用他然後去生成一些一致的主題,反復被提到的問題,然後重複出現的結構等等這些東西,他本身上我們是用概率去對抗這個不穩定性,你不能說一個藥他有99%的作用,他可能在某些人身上產生副作用,你不能說他是好的,完全好的,也不能說他是完全壞的。 你只能透過概率去搞這件事情,把概率盡量提高。 所以我們怎麼利用這個大型模型呢?首先我們的role我們要保留嘛,然後我們盡量分類擴展嘛,然後做信息壓縮是很晚才做的,為什麼要很晚?因為一旦做信息壓縮你就回不去了。 信息壓縮是什麼呢?就是大型模型經常出現的地方summary,
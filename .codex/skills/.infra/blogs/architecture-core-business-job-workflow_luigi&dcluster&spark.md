# DataVisor æ ¸å¿ƒä¸šåŠ¡è¿è½¬æ¶æ„åˆ†æ

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æ DataVisor å¹³å°çš„æ ¸å¿ƒä¸šåŠ¡æ¶æ„ï¼Œæ¶µç›–äº†ä»æ•°æ®æ¥å…¥åˆ°ç»“æœè¾“å‡ºçš„å®Œæ•´é“¾è·¯ï¼ŒåŒ…æ‹¬ **Cron è°ƒåº¦**ã€**Luigi ä»»åŠ¡ç¼–æ’**ã€**DCluster èµ„æºç®¡ç†**ã€**Feature Platform (FP) ç‰¹å¾è®¡ç®—** å’Œ **æ•°æ®å­˜å‚¨** äº”å¤§æ ¸å¿ƒç»„ä»¶ã€‚

---

## ğŸ¯ æ¶æ„å…¨æ™¯å›¾

```mermaid
graph TB
    subgraph "â˜ï¸ AWS äº‘åŸºç¡€è®¾æ–½"
        S3[("Client S3<br/>Raw Data")]
        EC2OnDemand["On-Demand EC2<br/>(Long-lived/ç¨³å®š)"]
        SpotEC2["Spot Instance<br/>(Triggered/æˆæœ¬ä¼˜åŒ–)"]
        Spark["Spark Jobs"]
        Flink["Flink Jobs"]
    end
    
    subgraph "ğŸ›ï¸ K8s é›†ç¾¤ - è°ƒåº¦ç¼–æ’å±‚"
        LuigiPod["Luigi Pod<br/>(luigi-deployment)"]
        CronJobs["Cron Jobs<br/>(å®šæ—¶ä»»åŠ¡)"]
        DCluster["DCluster Service<br/>(ä»»åŠ¡ç®¡ç†)"]
    end
    
    subgraph "ğŸ”„ Luigi ä»»åŠ¡ç¼–æ’"
        Connector["Connector<br/>(Fetcher, Processor)"]
        LogOrganizer["LogTimeFileOrganizer"]
        VirtualNode["VirtualNodeGenerator"]
        CronFPFerry["CronFeaturePlatformFerry"]
        BatchFPFerry["BatchFeaturePlatformFerry"]
    end
    
    subgraph "ğŸ§® Feature Platform (FP)"
        FP["FP Service<br/>(å®æ—¶/æ‰¹å¤„ç†ç‰¹å¾è®¡ç®—)"]
    end
    
    subgraph "ğŸ’¾ æ•°æ®å¤„ç†æµæ°´çº¿"
        Rawlogconverter["Rawlogconverter"]
        Campaign["Campaign"]
        UserStats["UserStats"]
        ResultAgg["ResultAgg"]
        EventJoin["EventJoinLite"]
        FrontendGen["FrontendResultGenerator"]
    end
    
    subgraph "ğŸ—„ï¸ æ•°æ®å­˜å‚¨å±‚"
        Cassandra[("Cassandra<br/>(DFE, Results)")]
        S3Result[("Client S3<br/>Results")]
    end
    
    %% æ•°æ®æµå‘
    S3 -->|Raw Data| Connector
    CronJobs -->|Schedule| Connector
    CronJobs -->|Schedule| LogOrganizer
    CronJobs -->|Schedule| VirtualNode
    
    Connector -->|Raw Data & Client Data| LogOrganizer
    LogOrganizer -->|Pre-DFE| VirtualNode
    VirtualNode -->|Virtual Node| BatchFPFerry
    
    CronFPFerry -->|Real-time| FP
    BatchFPFerry -->|Batch| FP
    
    VirtualNode -->|DFE Data| Rawlogconverter
    Rawlogconverter -->|DFE| Cassandra
    
    Rawlogconverter --> Campaign
    Campaign --> ResultAgg
    UserStats --> ResultAgg
    ResultAgg --> EventJoin
    EventJoin --> FrontendGen
    FrontendGen -->|Results| S3Result
    
    LuigiPod -->|Manage| CronJobs
    DCluster -->|Trigger| Spark
    DCluster -->|Trigger| Flink
    DCluster -->|ä¼˜å…ˆä½¿ç”¨/æˆæœ¬ä¼˜åŒ–| SpotEC2
    DCluster -->|é™çº§ä½¿ç”¨/ç¨³å®šæ€§ä¿è¯| EC2OnDemand
    SpotEC2 -.->|è¿è¡Œ| Spark
    SpotEC2 -.->|è¿è¡Œ| Flink
    EC2OnDemand -.->|è¿è¡Œ| Spark
    EC2OnDemand -.->|è¿è¡Œ| Flink
    
    style FP fill:#bbdefb
    style DCluster fill:#c8e6c9
    style LuigiPod fill:#fff9c4
    style Cassandra fill:#f8bbd0
    style S3 fill:#dcedc8
```

---

## ğŸ—ï¸ äº”å¤§æ ¸å¿ƒç»„ä»¶

### 1ï¸âƒ£ Cron è°ƒåº¦å±‚ (å®šæ—¶ä»»åŠ¡ç®¡ç†)

**ä½ç½®**: K8s Luigi Pod (`luigi-deployment`)

**åŠŸèƒ½**: æä¾›å®šæ—¶ä»»åŠ¡è§¦å‘æœºåˆ¶ï¼Œæ˜¯æ•´ä¸ªç³»ç»Ÿçš„"å¿ƒè·³"

#### Cron é…ç½®ç¤ºä¾‹

```bash
# é«˜é¢‘ä»»åŠ¡ - æ¯ 5 åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
*/5 * * * * /bin/bash /home/datavisor/cronjob_20minute.sh +syncbank

# æ¯å°æ—¶ä»»åŠ¡ - æ¯å°æ—¶ç¬¬ 20 åˆ†é’Ÿæ‰§è¡Œ
20 * * * * /bin/bash /home/datavisor/cronjob_20minute.sh -syncbank -appsflyer -sofi -nasa

# å‡Œæ™¨ç»´æŠ¤ä»»åŠ¡ - æ¯å¤©å‡Œæ™¨ 3 ç‚¹æ‰§è¡Œ
0 3 * * * /bin/bash /home/datavisor/luigitasks_dcluster/batch_pipeline_daily_once_run.sh

# æ‰¹å¤„ç†çª—å£ - è·³è¿‡å¤œé—´ç»´æŠ¤æ—¶æ®µï¼ˆ4-5ç‚¹ï¼‰
45 0-3,6-23 * * * /bin/bash /home/datavisor/cronjob_20minute.sh +nasa

# Feature Platform Ferry - å‡Œæ™¨ 4-5 ç‚¹æ‰§è¡Œ
30 4,5 * * * /bin/bash /home/datavisor/luigitasks_dcluster/batch_pipeline_cronfpferry.sh +nasa

# æ‰¹å¤„ç†ä»»åŠ¡ - æ¯å°æ—¶ç¬¬ 50 åˆ†é’Ÿæ‰§è¡Œ
50 * * * * /bin/bash /home/datavisor/luigitasks_dcluster/batch_pipeline_hourly_run.sh

# æœˆåº¦ä»»åŠ¡ - æ¯æœˆ 1 å·å’Œ 15 å·æ‰§è¡Œ
0 0 1,15 * * /bin/bash /home/datavisor/luigitasks_dcluster/batch_pipeline_8hour_run.sh

# å‘¨åº¦ä»»åŠ¡ - æ¯æœˆ 7, 14, 21, 28 å·æ‰§è¡Œ
0 0 7,14,21,28 * * /bin/bash /home/datavisor/cronjob_monthly.sh
```

#### å…³é”®è°ƒåº¦è„šæœ¬

| è„šæœ¬åç§° | è°ƒåº¦é¢‘ç‡ | ä½œç”¨ |
|---------|---------|------|
| `cronjob_20minute.sh` | æ¯ 5-20 åˆ†é’Ÿ | è§¦å‘é«˜é¢‘æ•°æ®å¤„ç†ä»»åŠ¡ï¼ˆConnector, LogOrganizerï¼‰ |
| `batch_pipeline_cronfpferry.sh` | å‡Œæ™¨ 4-5 ç‚¹ | è§¦å‘ CronFeaturePlatformFerry ä»»åŠ¡ |
| `batch_pipeline_hourly_run.sh` | æ¯å°æ—¶ç¬¬ 50 åˆ†é’Ÿ | æ‰¹å¤„ç†å°æ—¶çº§ä»»åŠ¡ |
| `batch_pipeline_daily_once_run.sh` | æ¯å¤©å‡Œæ™¨ 3 ç‚¹ | æ—¥åº¦ç»´æŠ¤å’Œæ¸…ç†ä»»åŠ¡ |
| `batch_pipeline_8hour_run.sh` | æ¯æœˆ 2 æ¬¡ | é‡å‹æ‰¹å¤„ç†ä»»åŠ¡ |
| `cronjob_monthly.sh` | æ¯å‘¨ | æœˆåº¦ç»Ÿè®¡å’ŒæŠ¥å‘Šä»»åŠ¡ |

---

### 2ï¸âƒ£ Luigi ä»»åŠ¡ç¼–æ’å±‚ (ä¾èµ–ç®¡ç†)

**ä½ç½®**: K8s Luigi Pod ä¸­çš„ Luigi è¿›ç¨‹

**åŠŸèƒ½**: ç®¡ç†ä»»åŠ¡ä¾èµ–å…³ç³»ï¼Œç¡®ä¿ä»»åŠ¡æŒ‰æ­£ç¡®é¡ºåºæ‰§è¡Œ

#### Luigi æ ¸å¿ƒæ¦‚å¿µ

```python
# Luigi Task ç¤ºä¾‹
class MonitorTracker(luigi.Task):
    client = luigi.Parameter()
    date = luigi.DateParameter()
    
    def requires(self):
        # å®šä¹‰ä¾èµ–å…³ç³»
        return [
            Labeling(client=self.client, date=self.date),
            ResultSender(client=self.client, date=self.date)
        ]
    
    def run(self):
        # ä»»åŠ¡æ‰§è¡Œé€»è¾‘
        pass
    
    def complete(self):
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
        return self.output().exists()
```

#### Luigi ä»»åŠ¡ä¾èµ–å›¾

```mermaid
graph LR
    A[Connector] --> B[LogTimeFileOrganizer]
    B --> C[VirtualNodeGenerator]
    C --> D[Rawlogconverter]
    D --> E[Campaign]
    D --> F[UserStats]
    E --> G[ResultAggLite]
    F --> G
    G --> H[EventJoinLite]
    H --> I[ResultAgg]
    I --> J[FrontendResultGenerator]
    J --> K[FrontendResultWriter]
    K --> L[ResultSender]
    
    C --> M[BatchFeaturePlatformFerry]
    M -.->|å¼‚æ­¥| N[FP Service]
    
    style A fill:#ffccbc
    style L fill:#c8e6c9
    style N fill:#bbdefb
```

#### Luigi ä»»åŠ¡ç±»å‹

| ä»»åŠ¡ç±»å‹ | ç¤ºä¾‹ | ç‰¹ç‚¹ |
|---------|------|------|
| **æ•°æ®æŠ“å–** | Connector (Fetcher, Processor) | ä» S3 æ‹‰å–å®¢æˆ·åŸå§‹æ•°æ® |
| **æ•°æ®é¢„å¤„ç†** | LogTimeFileOrganizer | æ—¶é—´çª—å£ç»„ç»‡å’Œé¢„å¤„ç† |
| **ç‰¹å¾ç”Ÿæˆ** | VirtualNodeGenerator | ç”Ÿæˆè™šæ‹ŸèŠ‚ç‚¹ï¼Œå‡†å¤‡ DFE |
| **DFE è½¬æ¢** | Rawlogconverter | è½¬æ¢ä¸º DFE æ ¼å¼ |
| **DFE å­˜å‚¨** | CassandraDfeWriter | å†™å…¥ Cassandra |
| **ç‰¹å¾ä¼ è¾“** | CronFeaturePlatformFerry | ä¼ è¾“åˆ° FPï¼ˆå®æ—¶ï¼‰ |
| **æ‰¹é‡ä¼ è¾“** | BatchFeaturePlatformFerry | æ‰¹é‡ä¼ è¾“åˆ° FP |
| **æ•°æ®èšåˆ** | Campaign, UserStats, ResultAgg | å¤šç»´åº¦èšåˆç»Ÿè®¡ |
| **ç»“æœç”Ÿæˆ** | FrontendResultGenerator | ç”Ÿæˆå‰ç«¯å±•ç¤ºæ•°æ® |
| **ç»“æœä¼ è¾“** | ResultSender | å‘é€ç»“æœåˆ°å®¢æˆ· S3 |

#### Luigi è¿›ç¨‹ç¤ºä¾‹

åœ¨ Luigi Pod ä¸­è¿è¡Œçš„å®é™…è¿›ç¨‹ï¼š

```bash
# Luigi ä¸»è°ƒåº¦å™¨
/usr/local/bin/python /usr/local/bin/luigid

# Cron è§¦å‘çš„ä»»åŠ¡è„šæœ¬
/bin/bash /home/datavisor/cronjob_20minute.sh +syncbank

# Luigi Worker è¿›ç¨‹ç¤ºä¾‹
/usr/local/bin/python /usr/local/bin/luigi --module batch_tasks Labeling \
  --client=syncbank --workers=1 --date=2025-11-21

/usr/local/bin/python /usr/local/bin/luigi --module batch_tasks ResultSender \
  --client=syncbank --date=2025-11-21 --workers=5

/usr/local/bin/python /usr/local/bin/luigi --module batch_tasks SparkConnectorRunner \
  --client=syncbank --workers=1 --date=2025-11-21

/usr/local/bin/python /usr/local/bin/luigi --module batch_tasks CronFeaturePlatformFerry \
  --client=syncbank --workers=1 --date=2025-11-21

/usr/local/bin/python /usr/local/bin/luigi --module batch_tasks MonitorTracker \
  --client=syncbank --workers=1 --date=2025-11-21
```

---

### 3ï¸âƒ£ DCluster èµ„æºç®¡ç†å±‚ (Job æ‰§è¡Œ)

**ä½ç½®**: K8s DCluster Service

**åŠŸèƒ½**: ç®¡ç† Spark/Flink Job çš„ç”Ÿå‘½å‘¨æœŸï¼ŒåŠ¨æ€åˆ†é…è®¡ç®—èµ„æº

#### DCluster æ¶æ„

```mermaid
graph TB
    subgraph "DCluster Service"
        API["DCluster API<br/>(Job Management)"]
        Scheduler["Job Scheduler"]
        Monitor["Job Monitor"]
        ResourceMgr["Resource Manager<br/>(Spotç”³è¯·/é™çº§)"]
    end
    
    subgraph "AWS è®¡ç®—èµ„æº"
        EC2OnDemand["On-Demand EC2<br/>(é•¿æœŸè¿è¡Œ/ç¨³å®šæ€§ä¼˜å…ˆ)"]
        SpotInstance["Spot Instance<br/>(æŒ‰éœ€è§¦å‘/æˆæœ¬ä¼˜å…ˆ)"]
        SparkJob["Spark Jobs"]
        FlinkJob["Flink Jobs"]
    end
    
    API --> Scheduler
    Scheduler --> ResourceMgr
    ResourceMgr -->|ç¨³å®šæ€§ä¼˜å…ˆ| EC2OnDemand
    ResourceMgr -->|æˆæœ¬ä¼˜å…ˆ| SpotInstance
    ResourceMgr -.->|ç”³è¯·å¤±è´¥/è¶…æ—¶| Scheduler
    Scheduler --> SparkJob
    Scheduler --> FlinkJob
    EC2OnDemand --> SparkJob
    EC2OnDemand --> FlinkJob
    SpotInstance --> SparkJob
    SpotInstance --> FlinkJob
    Monitor -.->|Health Check| SparkJob
    Monitor -.->|Health Check| FlinkJob
    Monitor -.->|Spot ä¸å¯ç”¨æ£€æµ‹| ResourceMgr
    
    style API fill:#c8e6c9
    style EC2OnDemand fill:#ffccbc
    style SpotInstance fill:#ffe0b2
    style ResourceMgr fill:#fff9c4
```

#### DCluster ä¸»è¦åŠŸèƒ½

| åŠŸèƒ½ | è¯´æ˜ | API ç«¯ç‚¹ |
|------|------|---------|
| **Job æäº¤** | æäº¤æ–°çš„ Spark/Flink Job | `POST /cluster/job/submit` |
| **Job ç»ˆæ­¢** | ç»ˆæ­¢è¿è¡Œä¸­çš„ Job | `POST /cluster/job/terminate/{jobId}` |
| **Job æŸ¥è¯¢** | æŸ¥è¯¢ Job çŠ¶æ€ | `GET /cluster/job/{jobId}` |
| **Job åˆ—è¡¨** | è·å–æ‰€æœ‰ Job | `GET /cluster/jobs` |
| **èµ„æºåˆ†é…** | åŠ¨æ€åˆ†é… EC2/Spot èµ„æº | `POST /cluster/resources/allocate` |
| **Spot ç”³è¯·** | å°è¯•ç”³è¯· Spot Instance | `POST /cluster/resources/spot/request` |
| **Spot é™çº§** | Spot ä¸å¯ç”¨æ—¶é™çº§åˆ° On-Demand | `POST /cluster/resources/fallback` |
| **å¥åº·æ£€æŸ¥** | æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€ | `GET /cluster/health` |

#### EC2 èµ„æºç±»å‹å¯¹æ¯”

| ç‰¹æ€§ | On-Demand EC2 (é•¿æœŸè¿è¡Œ) | Spot Instance (æŒ‰éœ€è§¦å‘) |
|------|------------------------|----------------------|
| **æˆæœ¬** | æ ‡å‡†ä»·æ ¼ (100%) | æŠ˜æ‰£ä»·æ ¼ (30-90% off) |
| **ç¨³å®šæ€§** | é«˜ (ä¸ä¼šè¢«å›æ”¶) | ä¸­ (å¯èƒ½è¢« AWS å›æ”¶) |
| **å¯ç”¨æ€§** | ä¿è¯å¯ç”¨ | ä¸ä¿è¯ (å¯èƒ½ç”³è¯·å¤±è´¥) |
| **é€‚ç”¨åœºæ™¯** | å…³é”®ä»»åŠ¡ã€é•¿æ—¶é—´è¿è¡Œ | æ‰¹å¤„ç†ã€å¯å®¹é”™ä»»åŠ¡ |
| **å¯åŠ¨æ—¶é—´** | ç«‹å³å¯ç”¨ | å¯èƒ½éœ€è¦ç­‰å¾…æˆ–å¤±è´¥ |
| **DCluster ç­–ç•¥** | å¸¸é©»é›†ç¾¤ï¼Œä¼˜å…ˆçº§é«˜ | ä¼˜å…ˆå°è¯•ï¼Œå¤±è´¥åˆ™é™çº§ |

#### Spot Instance ç”³è¯·æµç¨‹

```mermaid
sequenceDiagram
    participant Luigi as Luigi Task
    participant DCluster as DCluster API
    participant AWS as AWS EC2 API
    participant Job as Spark/Flink Job
    
    Note over Luigi,AWS: ğŸ¯ Cost ä¼˜å…ˆç­–ç•¥
    Luigi->>DCluster: Submit Job Request
    DCluster->>DCluster: è¯„ä¼°èµ„æºéœ€æ±‚
    
    alt Spot Instance ä¼˜å…ˆ (æˆæœ¬ä¼˜åŒ–)
        DCluster->>AWS: Request Spot Instance
        alt Spot å¯ç”¨
            AWS-->>DCluster: Spot Instance Ready
            DCluster->>Job: Launch Job on Spot
            Job-->>Luigi: Job Running (Low Cost)
        else Spot ä¸å¯ç”¨ (èµ„æºç´§å¼ )
            AWS-->>DCluster: Spot Request Failed
            Note over DCluster: ç­‰å¾…è¶…æ—¶æˆ–ç«‹å³é™çº§
            DCluster->>AWS: Request On-Demand EC2
            AWS-->>DCluster: On-Demand Ready
            DCluster->>Job: Launch Job on On-Demand
            Job-->>Luigi: Job Running (Standard Cost)
        end
    else å…³é”®ä»»åŠ¡ (ç¨³å®šæ€§ä¼˜å…ˆ)
        DCluster->>AWS: Request On-Demand EC2
        AWS-->>DCluster: On-Demand Ready
        DCluster->>Job: Launch Job on On-Demand
        Job-->>Luigi: Job Running (Guaranteed)
    end
    
    Note over DCluster,Job: ç›‘æ§ Spot å›æ”¶é£é™©
    loop Health Check
        DCluster->>Job: Check Job Status
        alt Spot è¢« AWS å›æ”¶
            AWS->>DCluster: Spot Termination Notice
            DCluster->>Job: Graceful Shutdown
            DCluster->>AWS: Request On-Demand EC2
            DCluster->>Job: Restart Job on On-Demand
        end
    end
```

#### Spot Instance æ•…éšœå¤„ç†

| æ•…éšœåœºæ™¯ | æ£€æµ‹æ–¹å¼ | å¤„ç†ç­–ç•¥ | é¢„æœŸæ—¶é—´ |
|---------|---------|---------|---------|
| **Spot ç”³è¯·è¶…æ—¶** | ç”³è¯·æ—¶é—´ > 5 åˆ†é’Ÿ | åœæ­¢ç”³è¯·ï¼Œé™çº§åˆ° On-Demand | 5-10 åˆ†é’Ÿ |
| **Spot æŒç»­ä¸å¯ç”¨** | è¿ç»­ 3 æ¬¡ç”³è¯·å¤±è´¥ | æš‚æ—¶ç¦ç”¨ Spotï¼Œä½¿ç”¨ On-Demand | ç«‹å³ |
| **Spot è¢« AWS å›æ”¶** | AWS 2 åˆ†é’Ÿæå‰é€šçŸ¥ | ä¿å­˜çŠ¶æ€ï¼Œè¿ç§»åˆ° On-Demand | 2-5 åˆ†é’Ÿ |
| **Job æ‰§è¡Œä¸­æ–­** | å¥åº·æ£€æŸ¥å¤±è´¥ | DCluster ç»ˆæ­¢ Jobï¼Œé‡æ–°è°ƒåº¦ | 5-10 åˆ†é’Ÿ |
| **èµ„æºå®Œå…¨ä¸å¯ç”¨** | æ‰€æœ‰ EC2 ç±»å‹éƒ½å¤±è´¥ | å‘Šè­¦é€šçŸ¥ï¼Œä»»åŠ¡è¿›å…¥ç­‰å¾…é˜Ÿåˆ— | ç­‰å¾…æ¢å¤ |

#### DCluster Job ç”Ÿå‘½å‘¨æœŸ

```mermaid
stateDiagram-v2
    [*] --> Pending: Submit Job
    Pending --> Running: Resources Allocated
    Running --> Completed: Success
    Running --> Failed: Error
    Running --> Terminated: Manual Stop
    Completed --> [*]
    Failed --> [*]
    Terminated --> [*]
    
    Running --> Hanging: Timeout/Stuck
    Hanging --> Terminated: Terminate API
```

#### DCluster Namespace å‘½åè§„åˆ™

```bash
# Namespace æ ¼å¼: s-{env}-{client}-{jobId}
s-prod-syncbank-abc123def456
s-prod-uopx-12345
s-prod-nasa-xyz789ghi012
```

#### DCluster API ä½¿ç”¨ç¤ºä¾‹

```bash
# æŸ¥è¯¢ DCluster Ingress
kubectl get ing -n prod | grep dcluster

# è¾“å‡ºç¤ºä¾‹
dcluster-uswest2-prod    dcluster-uswest2-prod.dv-api.com    80, 443    30d

# ç»ˆæ­¢ Hanging Job
curl -X POST http://dcluster-uswest2-prod.dv-api.com/cluster/job/terminate/abc123def456

# æŸ¥è¯¢ Job çŠ¶æ€
curl -X GET http://dcluster-uswest2-prod.dv-api.com/cluster/job/abc123def456
```

---

### 4ï¸âƒ£ Feature Platform (FP) ç‰¹å¾è®¡ç®—æœåŠ¡

**ä½ç½®**: K8s FP Service Pod

**åŠŸèƒ½**: æ ¸å¿ƒç‰¹å¾è®¡ç®—å¼•æ“ï¼Œæä¾›å®æ—¶å’Œæ‰¹å¤„ç†ç‰¹å¾è®¡ç®—

#### FP å·¥ä½œæ¨¡å¼

| æ¨¡å¼ | è§¦å‘æ–¹å¼ | æ•°æ®æ¥æº | å»¶è¿Ÿ | ç”¨é€” |
|------|---------|---------|------|------|
| **å®æ—¶æ¨¡å¼** | CronFeaturePlatformFerry | VirtualNode (å®æ—¶) | < 1 åˆ†é’Ÿ | å®æ—¶é£æ§å†³ç­– |
| **æ‰¹å¤„ç†æ¨¡å¼** | BatchFeaturePlatformFerry | VirtualNode (æ‰¹é‡) | 5-20 åˆ†é’Ÿ | æ‰¹é‡ç‰¹å¾è®¡ç®— |

#### FP æ•°æ®æµå‘

```mermaid
graph LR
    A[VirtualNode] --> B{Ferry Type}
    B -->|Cron| C[CronFeaturePlatformFerry]
    B -->|Batch| D[BatchFeaturePlatformFerry]
    
    C -->|Real-time| E[FP Service]
    D -->|Batch| E
    
    E --> F[Feature Computation]
    F --> G[Feature Storage]
    G --> H[Feature API]
    
    style E fill:#bbdefb
    style C fill:#fff9c4
    style D fill:#c8e6c9
```

#### FP ç‰¹å¾ç±»å‹

```python
# ç‰¹å¾ç±»å‹ç¤ºä¾‹
class FeatureTypes:
    # ç”¨æˆ·è¡Œä¸ºç‰¹å¾
    USER_BEHAVIOR = [
        "login_frequency",
        "transaction_amount",
        "device_changes"
    ]
    
    # è®¾å¤‡æŒ‡çº¹ç‰¹å¾
    DEVICE_FINGERPRINT = [
        "device_id",
        "ip_address",
        "browser_fingerprint"
    ]
    
    # ç½‘ç»œå…³ç³»ç‰¹å¾
    NETWORK_GRAPH = [
        "connected_devices",
        "shared_attributes",
        "graph_centrality"
    ]
    
    # æ—¶é—´åºåˆ—ç‰¹å¾
    TIME_SERIES = [
        "transaction_velocity",
        "login_pattern",
        "spending_pattern"
    ]
```

---

### 5ï¸âƒ£ æ•°æ®å­˜å‚¨å±‚

#### Cassandra (ä¸»å­˜å‚¨)

**ç”¨é€”**: å­˜å‚¨ DFE (Digital Feature Extraction) æ•°æ®å’Œè®¡ç®—ç»“æœ

**æ•°æ®æ¨¡å‹**:
```cql
-- DFE è¡¨ç»“æ„
CREATE TABLE dfe_data (
    client_id TEXT,
    user_id TEXT,
    timestamp TIMESTAMP,
    feature_vector MAP<TEXT, DOUBLE>,
    PRIMARY KEY ((client_id, user_id), timestamp)
) WITH CLUSTERING ORDER BY (timestamp DESC);

-- ç»“æœè¡¨ç»“æ„
CREATE TABLE results (
    client_id TEXT,
    job_id TEXT,
    result_type TEXT,
    result_data TEXT,
    created_at TIMESTAMP,
    PRIMARY KEY ((client_id, job_id), result_type)
);
```

#### S3 (æ•°æ®æ¹–)

**ç”¨é€”**: 
- **è¾“å…¥**: å®¢æˆ·åŸå§‹æ•°æ® (`client S3 rawdata`)
- **è¾“å‡º**: å¤„ç†ç»“æœå’ŒæŠ¥å‘Š (`client S3 results`)

**S3 è·¯å¾„ç»“æ„**:
```
s3://client-bucket/
â”œâ”€â”€ rawdata/
â”‚   â”œâ”€â”€ {client}/
â”‚   â”‚   â”œâ”€â”€ {date}/
â”‚   â”‚   â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”‚   â””â”€â”€ transactions/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ {client}/
â”‚   â”‚   â”œâ”€â”€ {date}/
â”‚   â”‚   â”‚   â”œâ”€â”€ risk_scores/
â”‚   â”‚   â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”‚   â””â”€â”€ frontend_data/
```

---

## ğŸ”„ å®Œæ•´ä¸šåŠ¡æµç¨‹ä¸²è”

### ç«¯åˆ°ç«¯æ•°æ®æµ

```mermaid
sequenceDiagram
    participant S3 as Client S3 (Input)
    participant Cron as Cron Scheduler
    participant Luigi as Luigi Orchestrator
    participant DCluster as DCluster Manager
    participant Spark as Spark Jobs
    participant FP as Feature Platform
    participant Cassandra as Cassandra DB
    participant S3Out as Client S3 (Output)
    
    Note over Cron: â° å®šæ—¶è§¦å‘ (æ¯ 5-20 åˆ†é’Ÿ)
    Cron->>Luigi: Trigger cronjob_20minute.sh
    
    Note over Luigi: ğŸ“‹ ä»»åŠ¡ç¼–æ’
    Luigi->>Luigi: Start Connector Task
    Luigi->>S3: Fetch Raw Data
    S3-->>Luigi: Raw Data
    
    Luigi->>Luigi: LogTimeFileOrganizer
    Luigi->>Luigi: VirtualNodeGenerator
    
    Note over Luigi,FP: ğŸš¢ Feature Ferry (ä¸¤ç§æ¨¡å¼)
    par Real-time Ferry
        Luigi->>FP: CronFeaturePlatformFerry
    and Batch Ferry
        Luigi->>FP: BatchFeaturePlatformFerry
    end
    
    Note over FP: ğŸ§® ç‰¹å¾è®¡ç®—
    FP->>FP: Feature Computation
    
    Note over Luigi,Spark: ğŸ”§ é‡å‹è®¡ç®—ä»»åŠ¡
    Luigi->>DCluster: Submit Spark Job
    DCluster->>Spark: Allocate & Run
    Spark->>Spark: Rawlogconverter
    Spark->>Cassandra: Write DFE Data
    
    Note over Luigi: ğŸ“Š æ•°æ®èšåˆä¸ç»“æœç”Ÿæˆ
    Luigi->>Luigi: Campaign
    Luigi->>Luigi: UserStats
    Luigi->>Luigi: ResultAgg
    Luigi->>Luigi: EventJoinLite
    Luigi->>Luigi: FrontendResultGenerator
    Luigi->>Luigi: FrontendResultWriter
    
    Note over Luigi: ğŸ“¤ ç»“æœè¾“å‡º
    Luigi->>S3Out: ResultSender
    S3Out-->>S3Out: Store Results
    
    Note over DCluster: ğŸ§¹ æ¸…ç†èµ„æº
    DCluster->>Spark: Terminate Job
    DCluster->>DCluster: Release Resources
```

### è¯¦ç»†æ‰§è¡Œæ­¥éª¤

#### é˜¶æ®µ 1: æ•°æ®æ¥å…¥ (0-5 åˆ†é’Ÿ)

```mermaid
graph LR
    A[Cron Trigger] --> B[Connector Fetcher]
    B --> C[Download from S3]
    C --> D[Connector Processor]
    D --> E[Raw Data]
    D --> F[Client Data]
    
    style A fill:#fff9c4
    style E fill:#c8e6c9
    style F fill:#c8e6c9
```

**å…³é”®æ­¥éª¤**:
1. **Cron è§¦å‘**: `cronjob_20minute.sh +syncbank`
2. **Luigi å¯åŠ¨**: `Connector` Task
3. **æ•°æ®ä¸‹è½½**: ä» `s3://client-bucket/rawdata/{client}/{date}/` ä¸‹è½½
4. **æ•°æ®å¤„ç†**: è§£æã€æ¸…æ´—ã€æ ¼å¼è½¬æ¢
5. **è¾“å‡º**: `rawdata/` å’Œ `clientdata/` ç›®å½•

#### é˜¶æ®µ 2: æ•°æ®é¢„å¤„ç† (5-10 åˆ†é’Ÿ)

```mermaid
graph LR
    A[Raw Data] --> B[LogTimeFileOrganizer]
    B --> C[Time-windowed Logs]
    C --> D[VirtualNodeGenerator]
    D --> E[VirtualNode]
    E --> F[Pre-DFE]
    
    style A fill:#c8e6c9
    style E fill:#bbdefb
    style F fill:#ffe0b2
```

**å…³é”®æ­¥éª¤**:
1. **æ—¶é—´ç»„ç»‡**: `LogTimeFileOrganizer` æŒ‰æ—¶é—´çª—å£ç»„ç»‡æ—¥å¿—
2. **è™šæ‹ŸèŠ‚ç‚¹ç”Ÿæˆ**: `VirtualNodeGenerator` åˆ›å»ºè®¡ç®—èŠ‚ç‚¹
3. **Pre-DFE å‡†å¤‡**: å‡†å¤‡ DFE è¾“å…¥æ•°æ®

#### é˜¶æ®µ 3: ç‰¹å¾è®¡ç®— (10-20 åˆ†é’Ÿ)

```mermaid
graph TB
    A[VirtualNode] --> B{Ferry åˆ†å‘}
    B -->|å®æ—¶| C[CronFeaturePlatformFerry]
    B -->|æ‰¹é‡| D[BatchFeaturePlatformFerry]
    
    C --> E[FP Service]
    D --> E
    
    E --> F[Feature Extraction]
    F --> G[Feature Aggregation]
    G --> H[Feature Storage]
    
    style E fill:#bbdefb
    style H fill:#f8bbd0
```

**å…³é”®æ­¥éª¤**:
1. **Ferry è°ƒåº¦**: æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹© Ferry æ¨¡å¼
2. **FP è®¡ç®—**: ç‰¹å¾æå–ã€èšåˆã€å­˜å‚¨
3. **å¹¶è¡Œå¤„ç†**: DFE è½¬æ¢åŒæ—¶è¿›è¡Œ

#### é˜¶æ®µ 4: DFE è½¬æ¢ä¸å­˜å‚¨ (10-25 åˆ†é’Ÿ)

```mermaid
graph LR
    A[VirtualNode] --> B[DCluster]
    B --> C[Spark Job]
    C --> D[Rawlogconverter]
    D --> E[DFE]
    E --> F[CassandraDfeWriter]
    F --> G[(Cassandra)]
    
    style C fill:#ffccbc
    style G fill:#f8bbd0
```

**å…³é”®æ­¥éª¤**:
1. **Job æäº¤**: Luigi â†’ DCluster API
2. **Spark å¯åŠ¨**: åœ¨ AWS EC2 ä¸Šå¯åŠ¨ Spark Job
3. **DFE è½¬æ¢**: `Rawlogconverter` è½¬æ¢ä¸º DFE æ ¼å¼
4. **å†™å…¥ Cassandra**: `CassandraDfeWriter` æŒä¹…åŒ–

#### é˜¶æ®µ 5: æ•°æ®èšåˆä¸åˆ†æ (25-45 åˆ†é’Ÿ)

```mermaid
graph TB
    A[DFE Data] --> B[Rawlogconverter]
    B --> C[Campaign]
    B --> D[UserStats]
    C --> E[ResultAggLite]
    D --> E
    E --> F[EventJoinLite]
    F --> G[ResultAgg]
    
    style A fill:#f8bbd0
    style G fill:#c8e6c9
```

**å…³é”®æ­¥éª¤**:
1. **Campaign åˆ†æ**: æ´»åŠ¨çº§åˆ«èšåˆ
2. **UserStats è®¡ç®—**: ç”¨æˆ·ç»Ÿè®¡æŒ‡æ ‡
3. **ResultAggLite**: è½»é‡çº§ç»“æœèšåˆ
4. **EventJoinLite**: äº‹ä»¶å…³è”åˆ†æ
5. **ResultAgg**: æœ€ç»ˆç»“æœæ±‡æ€»

#### é˜¶æ®µ 6: å‰ç«¯æ•°æ®ç”Ÿæˆ (45-55 åˆ†é’Ÿ)

```mermaid
graph LR
    A[ResultAgg] --> B[CampaignFrontendData]
    A --> C[FrontendDataGen py]
    B --> D[FrontendResultGenerator]
    C --> D
    D --> E[FrontendResultWriter]
    E --> F[Frontend Data]
    
    style F fill:#c8e6c9
```

**å…³é”®æ­¥éª¤**:
1. **æ•°æ®è½¬æ¢**: `CampaignFrontendData` å’Œ `FrontendDataGen`
2. **ç»“æœç”Ÿæˆ**: `FrontendResultGenerator` ç”Ÿæˆå‰ç«¯å±•ç¤ºæ•°æ®
3. **æ•°æ®å†™å…¥**: `FrontendResultWriter` å†™å…¥å­˜å‚¨

#### é˜¶æ®µ 7: ç»“æœè¾“å‡º (55-60 åˆ†é’Ÿ)

```mermaid
graph LR
    A[Frontend Data] --> B[ResultSender]
    B --> C[S3 Upload]
    C --> D[(Client S3<br/>Results)]
    
    style D fill:#dcedc8
```

**å…³é”®æ­¥éª¤**:
1. **ç»“æœæ”¶é›†**: `ResultSender` æ”¶é›†æ‰€æœ‰ç»“æœ
2. **ä¸Šä¼  S3**: ä¸Šä¼ åˆ° `s3://client-bucket/results/{client}/{date}/`
3. **é€šçŸ¥å®¢æˆ·**: å‘é€å®Œæˆé€šçŸ¥

---

## âš™ï¸ å…³é”®é…ç½®ä¸å‚æ•°

### Luigi é…ç½®

```ini
# luigi.cfg
[core]
default-scheduler-host = localhost
default-scheduler-port = 8082
parallel-scheduling = true
workers = 5

[resources]
# å¹¶å‘é™åˆ¶
spark_jobs = 3
flink_jobs = 2

[batch_tasks]
# ä»»åŠ¡è¶…æ—¶è®¾ç½®
timeout = 3600  # 1 å°æ—¶

[retcode]
# é‡è¯•ç­–ç•¥
already_running = 10
missing_data = 20
not_run = 25
task_failed = 30
scheduling_error = 35
```

### DCluster é…ç½®

```yaml
# dcluster-config.yaml
spark:
  driver_memory: 4g
  executor_memory: 8g
  executor_cores: 4
  num_executors: 10

flink:
  jobmanager_memory: 2g
  taskmanager_memory: 4g
  taskmanager_slots: 4

resources:
  # EC2 èµ„æºé…ç½®
  on_demand:
    instance_type: r5.2xlarge
    min_instances: 5          # å¸¸é©»æœ€å°å®ä¾‹æ•°
    max_instances: 10         # On-Demand æœ€å¤§å®ä¾‹æ•°
    priority: high            # å…³é”®ä»»åŠ¡ä¼˜å…ˆä½¿ç”¨
    
  spot_instance:
    instance_type: r5.2xlarge
    max_instances: 20         # Spot æœ€å¤§å®ä¾‹æ•°
    max_price: 0.5            # æœ€é«˜å‡ºä»· ($/å°æ—¶)
    timeout_minutes: 5        # ç”³è¯·è¶…æ—¶æ—¶é—´
    retry_attempts: 3         # é‡è¯•æ¬¡æ•°
    priority: cost_optimized  # æˆæœ¬ä¼˜åŒ–ä¼˜å…ˆ
    fallback_to_on_demand: true  # å¤±è´¥æ—¶é™çº§åˆ° On-Demand
    
  # èµ„æºåˆ†é…ç­–ç•¥
  allocation_strategy: cost_optimized  # cost_optimized | performance_optimized | balanced
  
  # æˆæœ¬ä¼˜åŒ–ç­–ç•¥ (ä¼˜å…ˆ Spot)
  cost_optimized:
    prefer_spot: true
    spot_percentage: 70       # ç›®æ ‡ 70% ä½¿ç”¨ Spot
    on_demand_percentage: 30  # 30% ä½¿ç”¨ On-Demand
    
  # æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ (ä¼˜å…ˆ On-Demand)
  performance_optimized:
    prefer_spot: false
    spot_percentage: 30
    on_demand_percentage: 70
    
  # å¼¹æ€§ä¼¸ç¼©é…ç½®
  autoscaling:
    scale_up_threshold: 0.8    # CPU/Memory > 80% æ—¶æ‰©å®¹
    scale_down_threshold: 0.3  # CPU/Memory < 30% æ—¶ç¼©å®¹
    scale_up_cooldown: 300     # æ‰©å®¹å†·å´æ—¶é—´ (ç§’)
    scale_down_cooldown: 600   # ç¼©å®¹å†·å´æ—¶é—´ (ç§’)
```

### Feature Platform é…ç½®

```yaml
# fp-config.yaml
feature_platform:
  mode: hybrid  # real-time, batch, hybrid
  
  real_time:
    max_qps: 10000
    timeout_ms: 100
    cache_ttl_seconds: 60
  
  batch:
    batch_size: 10000
    max_parallel_batches: 5
    timeout_minutes: 30
  
  storage:
    cassandra_keyspace: fp_features
    s3_bucket: fp-features-backup
```

---

## ğŸ” ç›‘æ§ä¸è°ƒè¯•

### MGT å¹³å°ç›‘æ§

**è®¿é—®åœ°å€**: `https://eng-mgt-a.dv-api.com/oncall/logs/production-job`

**ç›‘æ§æŒ‡æ ‡**:
- Hanging Jobsï¼ˆæŒ‚èµ·ä»»åŠ¡ï¼‰
- Job Exit Codesï¼ˆé€€å‡ºç ç»Ÿè®¡ï¼‰
- Job Durationï¼ˆä»»åŠ¡æ—¶é•¿ï¼‰
- Resource Usageï¼ˆèµ„æºä½¿ç”¨ï¼‰

**ç¤ºä¾‹ URL**:
```
# US West 2 Production é›†ç¾¤ç›‘æ§
https://eng-mgt-a.dv-api.com/oncall/logs/production-job?area=aws-uswest2-prod_a_prod&client=syncbank&module=monitortracker&exitCode=

# EU West 1 Production é›†ç¾¤ç›‘æ§
https://eng-mgt-a.dv-api.com/oncall/logs/production-job?area=aws-euwest1-prod_b_prod&client=uopx&module=connector&exitCode=
```

### Luigi è°ƒè¯•å‘½ä»¤

```bash
# æŸ¥çœ‹ Luigi Pod
kubectl get pods -n prod -l app=luigi-deployment

# è¿›å…¥ Luigi Pod
kubectl exec -it -n prod luigi-deployment-xxxxx -- bash

# æŸ¥çœ‹æ‰€æœ‰ Luigi è¿›ç¨‹
ps aux | grep luigi | grep -v grep

# æŸ¥çœ‹ç‰¹å®šå®¢æˆ·ç«¯çš„ä»»åŠ¡
ps aux | grep -i syncbank

# æŸ¥çœ‹ç‰¹å®šæ¨¡å—çš„ä»»åŠ¡
ps aux | grep -i monitortracker

# æŸ¥çœ‹ Crontab é…ç½®
crontab -l
```

### DCluster è°ƒè¯•å‘½ä»¤

```bash
# æŸ¥çœ‹ DCluster Ingress
kubectl get ing -n prod | grep dcluster

# æŸ¥çœ‹å®¢æˆ·ç«¯ Job Namespace
kubectl get ns | grep s-prod-syncbank

# ç»ˆæ­¢ Hanging Job
curl -X POST http://dcluster-uswest2-prod.dv-api.com/cluster/job/terminate/{jobId}

# æŸ¥è¯¢ Job çŠ¶æ€
curl -X GET http://dcluster-uswest2-prod.dv-api.com/cluster/job/{jobId}
```

### å¸¸è§æ•…éšœæ’æŸ¥

| æ•…éšœç±»å‹ | ç—‡çŠ¶ | æ’æŸ¥æ­¥éª¤ | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|---------|
| **Hanging Job** | ä»»åŠ¡è¿è¡Œæ—¶é—´è¶…è¿‡å¹³å‡å€¼ 2-3 å€ | 1. æ£€æŸ¥ MGT å¹³å°<br/>2. æŸ¥çœ‹ DCluster namespace<br/>3. æ£€æŸ¥ Spark/Flink logs | ä½¿ç”¨ DCluster Terminate API |
| **Spot ç”³è¯·è¶…æ—¶** | Spot Instance ä¸€ç›´ç”³è¯·ä¸åˆ° | 1. æ£€æŸ¥ Spot ç”³è¯·æ—¥å¿—<br/>2. æŸ¥çœ‹å½“å‰ Spot ä»·æ ¼<br/>3. æ£€æŸ¥å¯ç”¨åŒºèµ„æº | DCluster è‡ªåŠ¨åœæ­¢ç”³è¯·ï¼Œé™çº§åˆ° On-Demand |
| **Spot é¢‘ç¹å›æ”¶** | Job é¢‘ç¹è¢«ä¸­æ–­é‡å¯ | 1. æŸ¥çœ‹ AWS Spot ä¸­æ–­é€šçŸ¥<br/>2. æ£€æŸ¥ Job checkpoint é…ç½®<br/>3. è¯„ä¼°ä»»åŠ¡ä¼˜å…ˆçº§ | åˆ‡æ¢åˆ° On-Demand æˆ–å¢åŠ  checkpoint é¢‘ç‡ |
| **æˆæœ¬å¼‚å¸¸å‡é«˜** | Spot ä½¿ç”¨ç‡ä¸‹é™ï¼ŒOn-Demand ä½¿ç”¨ç‡ä¸Šå‡ | 1. æ£€æŸ¥ Spot å¯ç”¨æ€§<br/>2. æŸ¥çœ‹ä»»åŠ¡åˆ†ç±»ç­–ç•¥<br/>3. åˆ†æèµ„æºä½¿ç”¨è¶‹åŠ¿ | è°ƒæ•´ Spot ä»·æ ¼ä¸Šé™æˆ–ä¼˜åŒ–ä»»åŠ¡è°ƒåº¦æ—¶é—´ |
| **Luigi Stuck** | Luigi è¿›ç¨‹å¡ä½ä¸åŠ¨ | 1. è¿›å…¥ Luigi Pod<br/>2. `ps aux` æŸ¥çœ‹è¿›ç¨‹<br/>3. æ£€æŸ¥è¿›ç¨‹ CPU/Memory | `kill PID` æˆ– `kill -9 PID` |
| **FP Timeout** | Feature Platform è¶…æ—¶ | 1. æ£€æŸ¥ FP Pod çŠ¶æ€<br/>2. æŸ¥çœ‹ FP logs<br/>3. æ£€æŸ¥ Ferry é˜Ÿåˆ— | é‡å¯ Ferry æˆ–å¢åŠ  FP èµ„æº |
| **Cassandra Write Fail** | DFE å†™å…¥å¤±è´¥ | 1. æ£€æŸ¥ Cassandra è¿æ¥<br/>2. æŸ¥çœ‹è¡¨ç©ºé—´ä½¿ç”¨ç‡<br/>3. æ£€æŸ¥å†™å…¥æƒé™ | æ‰©å®¹ Cassandra æˆ–ä¿®å¤è¿æ¥ |
| **S3 Upload Fail** | ç»“æœä¸Šä¼ å¤±è´¥ | 1. æ£€æŸ¥ S3 æƒé™<br/>2. æ£€æŸ¥ç½‘ç»œè¿æ¥<br/>3. éªŒè¯ bucket è·¯å¾„ | ä¿®å¤ IAM è§’è‰²æˆ–ç½‘ç»œé…ç½® |

### Spot Instance è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥ DCluster Spot ç”³è¯·çŠ¶æ€
curl -X GET http://dcluster-uswest2-prod.dv-api.com/cluster/resources/spot/status

# æŸ¥çœ‹ Spot ç”³è¯·å†å²
curl -X GET http://dcluster-uswest2-prod.dv-api.com/cluster/resources/spot/history?hours=24

# æŸ¥çœ‹å½“å‰ Spot ä»·æ ¼
aws ec2 describe-spot-price-history \
  --instance-types r5.2xlarge \
  --region us-west-2 \
  --start-time $(date -u +"%Y-%m-%dT%H:%M:%S") \
  --product-descriptions "Linux/UNIX" \
  --output table

# å¼ºåˆ¶åœæ­¢ Spot ç”³è¯· (å¦‚æœä¸€ç›´ç”³è¯·ä¸åˆ°)
curl -X POST http://dcluster-uswest2-prod.dv-api.com/cluster/resources/spot/cancel/{requestId}

# æŸ¥çœ‹ Spot ä¸­æ–­é€šçŸ¥
aws ec2 describe-spot-instance-requests \
  --region us-west-2 \
  --filters "Name=state,Values=active" \
  --output json | jq '.SpotInstanceRequests[] | select(.Status.Code == "instance-terminated-by-price")'

# æ£€æŸ¥ Job æ˜¯å¦è¿è¡Œåœ¨ Spot ä¸Š
kubectl get pods -n s-prod-{client}-{jobId} -o jsonpath='{.items[0].spec.nodeName}'
kubectl describe node {node-name} | grep "lifecycle=spot"
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ä¸ SLA

### ç«¯åˆ°ç«¯å»¶è¿Ÿ

| é˜¶æ®µ | ç›®æ ‡å»¶è¿Ÿ | P50 | P90 | P99 |
|------|---------|-----|-----|-----|
| **æ•°æ®æ¥å…¥** | < 5 åˆ†é’Ÿ | 3 åˆ†é’Ÿ | 5 åˆ†é’Ÿ | 8 åˆ†é’Ÿ |
| **æ•°æ®é¢„å¤„ç†** | < 10 åˆ†é’Ÿ | 8 åˆ†é’Ÿ | 12 åˆ†é’Ÿ | 18 åˆ†é’Ÿ |
| **ç‰¹å¾è®¡ç®—** | < 20 åˆ†é’Ÿ | 15 åˆ†é’Ÿ | 22 åˆ†é’Ÿ | 30 åˆ†é’Ÿ |
| **DFE è½¬æ¢** | < 25 åˆ†é’Ÿ | 20 åˆ†é’Ÿ | 28 åˆ†é’Ÿ | 35 åˆ†é’Ÿ |
| **æ•°æ®èšåˆ** | < 45 åˆ†é’Ÿ | 35 åˆ†é’Ÿ | 50 åˆ†é’Ÿ | 65 åˆ†é’Ÿ |
| **å‰ç«¯ç”Ÿæˆ** | < 55 åˆ†é’Ÿ | 45 åˆ†é’Ÿ | 60 åˆ†é’Ÿ | 75 åˆ†é’Ÿ |
| **ç»“æœè¾“å‡º** | < 60 åˆ†é’Ÿ | 50 åˆ†é’Ÿ | 65 åˆ†é’Ÿ | 80 åˆ†é’Ÿ |
| **æ€»å»¶è¿Ÿ** | < 60 åˆ†é’Ÿ | 50 åˆ†é’Ÿ | 70 åˆ†é’Ÿ | 90 åˆ†é’Ÿ |

### ååé‡æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å½“å‰å€¼ |
|------|-------|-------|
| **æ¯æ—¥å¤„ç†å®¢æˆ·æ•°** | 50+ | 56 |
| **æ¯å°æ—¶ä»»åŠ¡æ•°** | 1000+ | 1200 |
| **æ¯ç§’ç‰¹å¾è®¡ç®—** | 10000+ | 12000 |
| **DFE å†™å…¥é€Ÿç‡** | 5000 rows/s | 6000 rows/s |
| **S3 ä¸Šä¼ é€Ÿç‡** | 100 MB/s | 120 MB/s |

### å¯ç”¨æ€§ SLA

| æœåŠ¡ | ç›®æ ‡å¯ç”¨æ€§ | å½“å‰å¯ç”¨æ€§ |
|------|-----------|-----------|
| **Luigi è°ƒåº¦å™¨** | 99.9% | 99.95% |
| **DCluster æœåŠ¡** | 99.5% | 99.7% |
| **Feature Platform** | 99.9% | 99.92% |
| **Cassandra** | 99.99% | 99.98% |
| **S3** | 99.99% | 99.99% |

---

## ğŸš€ æ‰©å±•æ€§ä¸ä¼˜åŒ–

### æ°´å¹³æ‰©å±•ç­–ç•¥

```yaml
# HPA (Horizontal Pod Autoscaler) é…ç½®
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: luigi-deployment-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: luigi-deployment
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

| ä¼˜åŒ–æ–¹å‘ | å»ºè®® | é¢„æœŸæå‡ |
|---------|------|---------|
| **Luigi å¹¶å‘** | å¢åŠ  workers æ•°é‡åˆ° 10 | ååé‡ +30% |
| **Spark èµ„æº** | å¢åŠ  executor memory åˆ° 16g | æ€§èƒ½ +40% |
| **Cassandra è°ƒä¼˜** | è°ƒæ•´ compaction strategy | å†™å…¥æ€§èƒ½ +25% |
| **S3 å¹¶è¡Œä¸Šä¼ ** | ä½¿ç”¨ multipart upload | ä¸Šä¼ é€Ÿåº¦ +50% |
| **Feature Platform ç¼“å­˜** | å¢åŠ  cache TTL åˆ° 300s | å“åº”æ—¶é—´ -60% |
| **æ•°æ®åˆ†åŒº** | æŒ‰æ—¥æœŸå’Œå®¢æˆ·ç«¯åˆ†åŒº | æŸ¥è¯¢æ€§èƒ½ +35% |

### æˆæœ¬ä¼˜åŒ–å»ºè®®

| ä¼˜åŒ–æ–¹å‘ | å»ºè®® | é¢„æœŸèŠ‚çœ |
|---------|------|---------|
| **Spot Instance ä¼˜å…ˆ** | 70% ä»»åŠ¡ä½¿ç”¨ Spot Instance | æˆæœ¬ -50% |
| **Spot å¤šå¯ç”¨åŒº** | é…ç½®å¤šä¸ª AZ æé«˜ Spot å¯ç”¨æ€§ | å¯ç”¨æ€§ +30% |
| **On-Demand é¢„ç•™** | å…³é”®ä»»åŠ¡ä½¿ç”¨ Reserved Instance | æˆæœ¬ -40% |
| **æ™ºèƒ½é™çº§ç­–ç•¥** | Spot ç”³è¯·è¶…æ—¶ < 5 åˆ†é’Ÿè‡ªåŠ¨é™çº§ | å»¶è¿Ÿ -20% |
| **Job æ£€æŸ¥ç‚¹** | Spark Job å¯ç”¨ checkpointï¼ŒSpot å›æ”¶æ—¶å¿«é€Ÿæ¢å¤ | é‡å¯æ—¶é—´ -70% |
| **èµ„æºå³è°ƒä¼˜** | æ ¹æ®å†å²æ•°æ®ä¼˜åŒ– executor é…ç½® | èµ„æºåˆ©ç”¨ç‡ +25% |
| **æ··åˆç­–ç•¥** | é«˜å³°æœŸå¢åŠ  On-Demandï¼Œä½å³°æœŸå…¨ Spot | æˆæœ¬ -30% |

### Cost vs Performance æƒè¡¡ç­–ç•¥

```mermaid
graph LR
    A[ä»»åŠ¡æäº¤] --> B{ä»»åŠ¡ä¼˜å…ˆçº§}
    
    B -->|å…³é”®ä»»åŠ¡| C[Performance ä¼˜å…ˆ]
    B -->|æ™®é€šä»»åŠ¡| D[Cost ä¼˜å…ˆ]
    B -->|æ‰¹å¤„ç†ä»»åŠ¡| E[Balanced]
    
    C --> F[100% On-Demand EC2]
    D --> G[100% Spot Instance]
    E --> H[70% Spot + 30% On-Demand]
    
    G --> I{Spot å¯ç”¨?}
    I -->|æ˜¯| J[ä½¿ç”¨ Spot<br/>æˆæœ¬ -50%]
    I -->|å¦| K[é™çº§ On-Demand<br/>ä¿è¯å®Œæˆ]
    
    H --> L{Spot å¯ç”¨?}
    L -->|æ˜¯| M[ä¼˜å…ˆ Spot<br/>æˆæœ¬ -35%]
    L -->|å¦| N[ä½¿ç”¨ On-Demand<br/>ä¿è¯ç¨³å®šæ€§]
    
    style C fill:#ffccbc
    style D fill:#c8e6c9
    style E fill:#fff9c4
```

#### ä»»åŠ¡åˆ†ç±»ç­–ç•¥

| ä»»åŠ¡ç±»å‹ | ä¼˜å…ˆçº§ | èµ„æºç­–ç•¥ | æˆæœ¬å½±å“ | é€‚ç”¨åœºæ™¯ |
|---------|-------|---------|---------|---------|
| **å®æ—¶ç‰¹å¾è®¡ç®—** | é«˜ | 100% On-Demand | æ ‡å‡†æˆæœ¬ | CronFeaturePlatformFerry |
| **DFE è½¬æ¢** | ä¸­ | 70% Spot + 30% On-Demand | -35% | Rawlogconverter |
| **æ•°æ®èšåˆ** | ä¸­ | 70% Spot + 30% On-Demand | -35% | Campaign, UserStats |
| **æ‰¹å¤„ç†ä»»åŠ¡** | ä½ | 100% Spot (å¯é‡è¯•) | -50% | æœˆåº¦æŠ¥å‘Šã€å†å²æ•°æ®å¤„ç† |
| **å‰ç«¯æ•°æ®ç”Ÿæˆ** | é«˜ | 100% On-Demand | æ ‡å‡†æˆæœ¬ | FrontendResultGenerator |
| **å¼€å‘æµ‹è¯•** | ä½ | 100% Spot | -50% | æµ‹è¯•ç¯å¢ƒä»»åŠ¡ |

---

## ğŸ”’ å®‰å…¨ä¸åˆè§„

### æ•°æ®åŠ å¯†

```yaml
# åŠ å¯†é…ç½®
encryption:
  # S3 æœåŠ¡ç«¯åŠ å¯†
  s3:
    server_side_encryption: AES256
    kms_key_id: arn:aws:kms:us-west-2:xxx:key/xxx
  
  # Cassandra ä¼ è¾“åŠ å¯†
  cassandra:
    client_encryption: true
    ssl_truststore_path: /etc/cassandra/truststore.jks
  
  # DFE æ•°æ®åŠ å¯†
  dfe:
    encryption_algorithm: AES-256-GCM
    key_rotation_days: 90
```

### è®¿é—®æ§åˆ¶

```yaml
# RBAC é…ç½®
rbac:
  luigi_pod:
    service_account: luigi-sa
    roles:
      - read_secrets
      - write_cassandra
      - access_s3
  
  dcluster:
    service_account: dcluster-sa
    roles:
      - manage_jobs
      - allocate_resources
      - access_ec2
  
  fp_service:
    service_account: fp-sa
    roles:
      - read_features
      - write_features
      - access_cache
```

### å®¡è®¡æ—¥å¿—

```yaml
# å®¡è®¡é…ç½®
audit:
  enabled: true
  log_level: INFO
  
  events:
    - job_submit
    - job_terminate
    - data_access
    - config_change
  
  storage:
    type: cloudwatch
    log_group: /datavisor/audit
    retention_days: 365
```

---

## ğŸ“š æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

âœ… **é«˜åº¦è‡ªåŠ¨åŒ–**: Cron + Luigi å®ç°å®Œå…¨è‡ªåŠ¨åŒ–çš„ä»»åŠ¡è°ƒåº¦å’Œä¾èµ–ç®¡ç†  
âœ… **å¼¹æ€§ä¼¸ç¼©**: DCluster åŠ¨æ€ç®¡ç† Spark/Flink èµ„æºï¼Œæ”¯æŒ Spot/On-Demand æ··åˆéƒ¨ç½²  
âœ… **æˆæœ¬ä¼˜åŒ–**: Spot Instance ä¼˜å…ˆç­–ç•¥ï¼Œæ‰¹å¤„ç†ä»»åŠ¡æˆæœ¬é™ä½ 50%  
âœ… **æ™ºèƒ½é™çº§**: Spot ä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§åˆ° On-Demandï¼Œä¿è¯ä»»åŠ¡å®Œæˆ  
âœ… **é«˜æ€§èƒ½**: Feature Platform æä¾›å®æ—¶å’Œæ‰¹å¤„ç†åŒæ¨¡å¼  
âœ… **é«˜å¯ç”¨**: å¤šåŒºåŸŸéƒ¨ç½²ï¼Œæ•…éšœè‡ªåŠ¨æ¢å¤ï¼ŒSpot å›æ”¶è‡ªåŠ¨è¿ç§»  
âœ… **å¯è§‚æµ‹æ€§**: MGT å¹³å°æä¾›å…¨é“¾è·¯ç›‘æ§

### æ¶æ„ç‰¹ç‚¹

ğŸ¯ **åˆ†å±‚è§£è€¦**: è°ƒåº¦ã€ç¼–æ’ã€æ‰§è¡Œã€è®¡ç®—ã€å­˜å‚¨äº”å±‚ç‹¬ç«‹  
ğŸ¯ **å®¹é”™è®¾è®¡**: ä»»åŠ¡å¤±è´¥è‡ªåŠ¨é‡è¯•ï¼Œèµ„æºä¸è¶³è‡ªåŠ¨æ‰©å®¹ï¼ŒSpot å›æ”¶è‡ªåŠ¨è¿ç§»  
ğŸ¯ **æˆæœ¬ä¼˜åŒ–**: Spot Instance ä¼˜å…ˆ + On-Demand ä¿åº•ï¼Œæˆæœ¬ä¸æ€§èƒ½åŠ¨æ€å¹³è¡¡  
ğŸ¯ **æ€§èƒ½ä¼˜åŒ–**: å¹¶è¡Œå¤„ç†ã€ç¼“å­˜æœºåˆ¶ã€èµ„æºæ± åŒ–  
ğŸ¯ **æ˜“äºç»´æŠ¤**: é›†ç¾¤åˆ«åã€ç»Ÿä¸€é…ç½®ã€è‡ªåŠ¨åŒ–éƒ¨ç½²

### Cost & Performance æ¶æ„è®¾è®¡åŸåˆ™

| è®¾è®¡åŸåˆ™ | è¯´æ˜ | å®ç°æ–¹å¼ |
|---------|------|---------|
| **æˆæœ¬ä¼˜å…ˆ** | éå…³é”®ä»»åŠ¡ä¼˜å…ˆä½¿ç”¨ Spot Instance | 70% æ‰¹å¤„ç†ä»»åŠ¡ä½¿ç”¨ Spotï¼Œæˆæœ¬é™ä½ 50% |
| **æ€§èƒ½ä¿åº•** | å…³é”®ä»»åŠ¡ä½¿ç”¨ On-Demand ä¿è¯ç¨³å®šæ€§ | å®æ—¶ç‰¹å¾è®¡ç®—ã€å‰ç«¯ç”Ÿæˆä½¿ç”¨ On-Demand |
| **æ™ºèƒ½é™çº§** | Spot ä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢ On-Demand | ç”³è¯·è¶…æ—¶ < 5 åˆ†é’Ÿè‡ªåŠ¨é™çº§ |
| **å®¹é”™è®¾è®¡** | Spot å›æ”¶æ—¶ä¿å­˜çŠ¶æ€å¹¶è¿ç§» | Spark Checkpoint + 2 åˆ†é’Ÿè¿ç§»çª—å£ |
| **åŠ¨æ€è°ƒæ•´** | æ ¹æ® Spot å¯ç”¨æ€§åŠ¨æ€è°ƒæ•´æ¯”ä¾‹ | é«˜å³°æœŸé™ä½ Spot æ¯”ä¾‹ï¼Œä½å³°æœŸæé«˜ |
| **å¤š AZ ç­–ç•¥** | å¤šå¯ç”¨åŒºç”³è¯·æé«˜ Spot å¯ç”¨æ€§ | é…ç½® 3 ä¸ª AZï¼Œæé«˜ 30% å¯ç”¨æ€§ |

### æœªæ¥æ¼”è¿›

ğŸš€ **Kubernetes Native**: è¿ç§»åˆ° Spark on K8sï¼Œå‡å°‘ EC2 ä¾èµ–  
ğŸš€ **å®æ—¶å¢å¼º**: æ‰©å±•å®æ—¶è®¡ç®—èƒ½åŠ›ï¼Œç¼©çŸ­ç«¯åˆ°ç«¯å»¶è¿Ÿ  
ğŸš€ **AI/ML é›†æˆ**: å¼•å…¥æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæå‡ç‰¹å¾è´¨é‡  
ğŸš€ **å¤šäº‘æ”¯æŒ**: æ”¯æŒ AWSã€GCPã€Azure å¤šäº‘éƒ¨ç½²  
ğŸš€ **Spot Fleet**: ä½¿ç”¨ Spot Fleet ç®¡ç†å¤šç§å®ä¾‹ç±»å‹ï¼Œæé«˜å¯ç”¨æ€§  
ğŸš€ **æˆæœ¬é¢„æµ‹**: AI é©±åŠ¨çš„ Spot ä»·æ ¼é¢„æµ‹ï¼Œæ™ºèƒ½é€‰æ‹©ç”³è¯·æ—¶æœº

---

## ğŸ’° æˆæœ¬ä¼˜åŒ–æ€»ç»“

### Spot Instance åœ¨æ¶æ„ä¸­çš„æ ¸å¿ƒä»·å€¼

DataVisor å¹³å°é€šè¿‡ **Spot Instance + On-Demand EC2 æ··åˆç­–ç•¥**ï¼Œå®ç°äº†æˆæœ¬ä¸æ€§èƒ½çš„æœ€ä½³å¹³è¡¡ï¼š

#### æˆæœ¬èŠ‚çœ

```
æ€»ä½“æˆæœ¬èŠ‚çœè®¡ç®—ï¼š
- æ‰¹å¤„ç†ä»»åŠ¡å æ¯”: 70%
- Spot Instance ä½¿ç”¨ç‡: 70% (åœ¨æ‰¹å¤„ç†ä»»åŠ¡ä¸­)
- Spot Instance æŠ˜æ‰£: 50%

æ€»ä½“èŠ‚çœ = 70% Ã— 70% Ã— 50% = 24.5%

å¦‚æœæœˆåº¦è®¡ç®—æˆæœ¬ $100,000ï¼š
- ä½¿ç”¨ Spot å: $75,500
- å¹´åº¦èŠ‚çœ: $294,000
```

#### å…³é”®è®¾è®¡å†³ç­–

| å†³ç­–ç‚¹ | é€‰æ‹© | åŸå›  |
|-------|------|------|
| **å®æ—¶ç‰¹å¾è®¡ç®—** | 100% On-Demand | å»¶è¿Ÿæ•æ„Ÿï¼Œä¸èƒ½å®¹å¿ä¸­æ–­ |
| **DFE è½¬æ¢** | 70% Spot + 30% On-Demand | å¯å®¹é”™ï¼Œæœ‰ checkpointï¼Œæˆæœ¬ä¼˜åŒ– |
| **æ•°æ®èšåˆ** | 70% Spot + 30% On-Demand | æ‰¹å¤„ç†æ€§è´¨ï¼Œå¯é‡è¯• |
| **å‰ç«¯ç”Ÿæˆ** | 100% On-Demand | å…³é”®è·¯å¾„ï¼Œä¿è¯ SLA |
| **Spot ç”³è¯·è¶…æ—¶** | 5 åˆ†é’Ÿ | å¹³è¡¡æˆæœ¬èŠ‚çœå’Œä»»åŠ¡å»¶è¿Ÿ |
| **è‡ªåŠ¨é™çº§** | å¯ç”¨ | ä¿è¯ä»»åŠ¡å®Œæˆï¼Œä¸ç‰ºç‰²å¯é æ€§ |

#### Spot Instance æœ€ä½³å®è·µ

âœ… **ä¼˜å…ˆä½¿ç”¨**: æ‰¹å¤„ç†ã€æ•°æ®èšåˆã€ç¦»çº¿è®¡ç®—ä»»åŠ¡  
âœ… **å¯ç”¨ Checkpoint**: Spark/Flink ä»»åŠ¡å®šæœŸä¿å­˜çŠ¶æ€  
âœ… **å¤š AZ éƒ¨ç½²**: æé«˜ Spot Instance å¯ç”¨æ€§  
âœ… **ä»·æ ¼ä¸Šé™è®¾ç½®**: é¿å…ä»·æ ¼æ³¢åŠ¨æ—¶æˆæœ¬å¤±æ§  
âœ… **å¥åº·æ£€æŸ¥**: ç›‘æ§ Spot ä¸­æ–­é€šçŸ¥ï¼Œæå‰è¿ç§»  
âœ… **è‡ªåŠ¨é™çº§**: ç”³è¯·å¤±è´¥æ—¶ç«‹å³åˆ‡æ¢ On-Demand  
âŒ **ä¸ä½¿ç”¨**: å®æ—¶è®¡ç®—ã€å…³é”®è·¯å¾„ã€æ— çŠ¶æ€ä¿å­˜çš„ä»»åŠ¡

#### DCluster èµ„æºç®¡ç†æ™ºèƒ½

DCluster ä½œä¸ºèµ„æºç®¡ç†æ ¸å¿ƒï¼Œå®ç°äº†ï¼š

1. **æ™ºèƒ½è°ƒåº¦**: æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹© Spot æˆ– On-Demand
2. **æ•…éšœæ£€æµ‹**: 5 åˆ†é’Ÿè¶…æ—¶æ£€æµ‹ï¼Œé¿å…æ— é™ç­‰å¾…
3. **è‡ªåŠ¨é™çº§**: Spot ä¸å¯ç”¨æ—¶ç§’çº§åˆ‡æ¢ On-Demand
4. **çŠ¶æ€ä¿å­˜**: Spot å›æ”¶å‰ä¿å­˜çŠ¶æ€ï¼ŒOn-Demand ç»§ç»­æ‰§è¡Œ
5. **æˆæœ¬ç›‘æ§**: å®æ—¶è·Ÿè¸ª Spot ä½¿ç”¨ç‡å’Œæˆæœ¬èŠ‚çœ

è¿™ç§è®¾è®¡ä½¿å¾— DataVisor å¹³å°æ—¢èƒ½äº«å— Spot Instance çš„æˆæœ¬ä¼˜åŠ¿ï¼Œåˆä¸ç‰ºç‰²ç³»ç»Ÿçš„å¯é æ€§å’Œæ€§èƒ½ï¼

---

## ğŸ“– ç›¸å…³æ–‡æ¡£

- [Luigi Debug Helper ä½¿ç”¨æŒ‡å—](./oncall-luigi-debug-helper.md)
- [K8s å‡çº§è®¡åˆ’](./operation-k8s-upgrade-plan.md)
- [è¯·æ±‚è·¯ç”±æ¶æ„](./architecture-request-routing-flow.md)
- [Grafana å»¶è¿Ÿç›‘æ§](./monitoring-grafana_latency_architecture.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¥æœŸ**: 2025-11-29  
**ç»´æŠ¤è€…**: DataVisor SRE Team


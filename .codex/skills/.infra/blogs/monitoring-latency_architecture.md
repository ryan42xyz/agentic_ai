# Grafana E2E Latency é¢æ¿æ¶æ„åˆ†æ

## guide book

`Cluster aws-useast1-prod-b has encountered some issues, detector rule: latency-p999-500ms, issued services: fp, reason: Latency: 1187ms, failed rate: 84.62%`

1. check infra's status
   1. qps - high
   2. pod - cpu/mem
   3. sla 
      1. sla - success rate
      2. qps 
      3. latency - å®Œæ•´çš„link process / ingress / apisix / upstream
2. yugabyte status
   1. cpu/mem
   2. speed / latency
3. @oncall-fp could you help check this one? yugabyte look like fine.

## related slack message
```
https://datavisor.slack.com/archives/CJT8ZPRJL/p1764047362404669

https://datavisor.slack.com/archives/CJT8ZPRJL/p1763353492281109
```
## related dashboard

### SLA: Ingress / Upstream Latency æŒ‡æ ‡å¯¹ç…§è¡¨ï¼ˆä¿®æ­£ç‰ˆï¼‰

| Panel åç§°ï¼ˆå½“å‰ï¼‰ | å»ºè®®æ ‡å‡†åç§° | å®é™…é‡åˆ°çš„å«ä¹‰ï¼ˆä¸¥æ ¼ï¼‰ | é“¾è·¯ä½ç½®ï¼ˆç²¾ç¡®ï¼‰ | å¸¸è§è¯¯è§£ç‚¹ | å®é™… Query |
|-------------------|------------|---------------------|----------------|----------|-----------|
| Response Percentiles from Ingress for $client from logql | `ingress_request_time_p95` | Ingress è§†è§’çš„ä¸€æ¬¡å®Œæ•´ä»£ç†è¯·æ±‚è€—æ—¶ï¼šä» ingress æ”¶åˆ°è¯·æ±‚å¼€å§‹ï¼Œåˆ° ingress å®Œæˆå“åº”è¿”å›ä¸ºæ­¢ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰ | Ingress â†’ Upstream â†’ Ingressï¼ˆæ•´ä½“ï¼‰ | âŒ ä¸æ˜¯ç«¯åˆ°ç«¯ç”¨æˆ·ä½“éªŒ<br>âŒ ä¸åŒ…å« clientâ†’ingress ç½‘ç»œ | `quantile_over_time(0.95, {namespace="ingress-nginx", client="$client", request_url=~".*(clientEvent...` |
| Upstream latency graph (Feature platform) | `ingress_upstream_latency_p95` | Ingress æˆåŠŸå°†è¯·æ±‚è½¬å‘ç»™ upstream åï¼Œåˆ° upstream è¿”å›å“åº”ä¸ºæ­¢çš„è€—æ—¶ï¼ˆä¸å« ingress å†…éƒ¨ç­‰å¾…ï¼‰ | Ingress â†” Upstream | âŒ ä¸ä»£è¡¨ä¸šåŠ¡"ç«¯åˆ°ç«¯"<br>âŒ ingress æ’é˜Ÿä¸ä¼šåæ˜ åœ¨è¿™é‡Œ | `quantile_over_time(0.95, {client="$client", pod=~".*", stream=~"stdout...` |
| Waiting Latency between Ingress and Upstream | `ingress_internal_waiting_latency_p95` | è¯·æ±‚å·²ç»åˆ°è¾¾ ingressï¼Œä½†å°šæœªï¼ˆæˆ–æœªå®Œå…¨ï¼‰åœ¨ upstream ä¸­æ‰§è¡Œæ—¶ï¼Œåœ¨ ingress å†…éƒ¨æ¶ˆè€—çš„æ—¶é—´ï¼ˆæ’é˜Ÿ / proxy / è°ƒåº¦ / bufferï¼‰ | Ingress å†…éƒ¨ | âš ï¸ ä¸ä¸€å®šæ˜¯"network issue"<br>âš ï¸ æ›´å¤šåæ˜  ingress è‡ªèº«å‹åŠ› | `quantile_over_time(0.95, {client="$client", pod=~".*", stream=~"stdout...` |

#### å…³é”®è¦ç‚¹

##### 1ï¸âƒ£ ä¸‰ä¸ªæŒ‡æ ‡çš„æ•°å­¦å…³ç³»

```
ingress_request_time
â‰ˆ ingress_upstream_latency
+ ingress_internal_waiting_latency
```

**æ³¨æ„ï¼š** è¿™æ˜¯ ingress è§†è§’çš„æ¨¡å‹ã€‚è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [Waiting Latency é¢æ¿è¯¦è§£](#4ï¸âƒ£-waiting-latency-between-ingress-and-upstream)ã€‚

##### 2ï¸âƒ£ Waiting Latency çš„å¿«é€Ÿç†è§£

**è®¡ç®—å…¬å¼**: `waiting_latency = request_time - upstream_response_time`

**å®é™…å«ä¹‰**: ingress å†…éƒ¨ç­‰å¾…/æ’é˜Ÿ/proxy/è°ƒåº¦/é™æµç­‰å¼€é”€

**âš ï¸ å¸¸è§è¯¯è§£**: ä¸ä¸€å®šæ˜¯"network issue"ï¼Œæ›´å¤šåæ˜  ingress è‡ªèº«å‹åŠ›

**è¯¦ç»†è¯´æ˜**: è¯·å‚è€ƒ [Waiting Latency é¢æ¿è¯¦è§£](#4ï¸âƒ£-waiting-latency-between-ingress-and-upstream) ç« èŠ‚ã€‚

##### 3ï¸âƒ£ åˆ†ä½æ•°é€‰æ‹©å»ºè®®

**Debug é˜¶æ®µï¼ˆP95ï¼‰ï¼š**

- **request_time P95** â†’ æ£€æµ‹æ˜¯å¦å­˜åœ¨æ˜æ˜¾ tail
- **upstream_latency P95** â†’ æ£€æµ‹åç«¯æ˜¯å¦æ…¢
- **waiting_latency P95** â†’ æ£€æµ‹ ingress æ˜¯å¦æœ‰æ’é˜Ÿ

**SLO / æ—¥å¸¸ç›‘æ§å»ºè®®ï¼š**

- **request_time**ï¼šP50 + P95
- **upstream_latency**ï¼šP50 / P75
- **waiting_latency**ï¼šP50ï¼ˆé¿å… tail è¯¯å¯¼ï¼‰

### nginx request_time (ç»å¯¹æ—¶é—´)
[ingress nginx access log](https://grafana-mgt.dv-api.com/explore?left=%7B%22datasource%22:%22Loki%22,%22queries%22:%5B%7B%22datasource%22:%7B%22type%22:%22loki%22,%22uid%22:%22M2q8i3Q7z%22%7D,%22expr%22:%22%7Bcluster%3D%5C%22aws-uswest2-prod-a%5C%22,namespace%3D%5C%22ingress-nginx%5C%22,pod%3D~%5C%22.*%5C%22,stream%3D~%5C%22stdout%7Cstderr%5C%22,container%3D%5C%22controller%5C%22%7D%5Cn%7C~%20%5C%22%2Fsofi%2Fupdate%20%5C%22%5Cn%7C%20pattern%20%5C%22%3C_%3E%20%3C_%3E%20%3C_%3E%20%5B%3C_%3E%5D%20%5C%5C%5C%22%3C_%3E%20%3C_%3E%20%3C_%3E%5C%5C%5C%22%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3C_%3E%20%3Crequest_time%3E%20%3C_%3E%20%3C_%3E%5C%22%5Cn%7C~%20%5C%22%20%5B0-9%5D%2B%20(0%5C%5C%5C%5C.00%5B5-9%5D%7C0%5C%5C%5C%5C.0%5B1-9%5D%5B0-9%5D*%7C0%5C%5C%5C%5C.%5B1-9%5D%5B0-9%5D*)%20200%20%5C%22%5Cn%22,%22refId%22:%22A%22%7D%5D,%22range%22:%7B%22from%22:%22now-2d%22,%22to%22:%22now%22%7D%7D&orgId=1)

ç¬¬ 13 ä½çš„ 0.001
ğŸ‘‰ request_timeï¼ˆclient â†’ ingress â†’ response å®Œæ•´è€—æ—¶ï¼‰

ç¬¬ 18 ä½çš„ 0.001 / 0.002
ğŸ‘‰ upstream_response_timeï¼ˆingress â†’ upstream â†’ ingress è¿™ä¸€è·³çš„è€—æ—¶ï¼‰

request_time	upstream_response_time	å«ä¹‰
0.001	0.001	åç«¯æå¿«ï¼Œingress å‡ ä¹æ— é¢å¤–å¼€é”€
0.002	0.001	ingress + client ä¾§å¤šäº† ~1ms
0.010	0.002	åç«¯å¿«ï¼Œä½† ingress/client æœ‰ç“¶é¢ˆ
0.200	0.180	æ˜æ˜¾æ˜¯åç«¯æ…¢
0.200	0.010	ingress / network / queue é—®é¢˜

```
client
  â†“
ingress-nginxï¼ˆæ¥æ”¶è¯·æ±‚ã€è§£æã€rewriteã€è½¬å‘ï¼‰
  â†“
upstream podï¼ˆçœŸæ­£çš„ä¸šåŠ¡æœåŠ¡ï¼‰
  â†“
ingress-nginxï¼ˆæ”¶åˆ° upstream å“åº”ã€å†™æ—¥å¿—ï¼‰
  â†“
client
```
ingress nginx access log format:
```
192.168.13.192 - - [1764334116.638] "POST /sofi/update HTTP/1.1" 200 5 "-" "ReactorNetty/1.2.10" 5667 0.001 [prod-fp-8080] [] 192.168.252.7:8080 5 0.001 200 96f3efd036ebe...

 1  192.168.13.192
 2  -
 3  -
 4  [1764334116.638]
 5  "POST
 6  /sofi/update
 7  HTTP/1.1"
 8  200
 9  5
10  "-"
11  "ReactorNetty/1.2.10"
12  5667
13  0.001   â† ä½ ä¹‹å‰ pattern æŠ“çš„å­—æ®µï¼ˆä¸å¯¹ï¼‰
14  [prod-fp-8080]
15  []
16  192.168.252.7:8080
17  5
18  0.001   â† ä½ çœŸæ­£æƒ³æŠ“çš„ upstream_response_time
19  200
20  trace_id

<_>                   # 1 client_ip
<_>                   # 2 -
<_>                   # 3 -
[<_>]                 # 4 timestamp
"<_>                  # 5 method
<_>                   # 6 path
<_>"                  # 7 protocol
<_>                   # 8 status
<_>                   # 9 body_bytes_sent
<_>                   # 10 "-"
<_>                   # 11 ua
<_>                   # 12 request_length
<_>                   # 13 rtime_client (ä½ ä¸éœ€è¦)
<_>                   # 14 [proxy]
<_>                   # 15 []
<_>                   # 16 upstream_addr
<_>                   # 17 upstream_status
<request_time>        # 18  ğŸ‘ˆ ä½ çœŸæ­£æƒ³æŠ“çš„ upstream_response_time
<_>                   # 19 repeated status
<_>                   # 20 trace id
```
`> 300ms (0.3s)`
```
{cluster="aws-uswest2-prod-a",namespace="ingress-nginx",pod=~".*",stream=~"stdout|stderr",container="controller"}
|~ "/sofi/update "
| pattern "<_> <_> <_> [<_>] \"<_> <_> <_>\" <_> <_> <_> <_> <_> <_> <_> <_> <_> <_> <request_time> <_> <_>"
|~ " [0-9]+ (0\\.[3-9][0-9]*|[1-9]\\.[0-9]+) 200 "

```

<!-- > 0.1s (100ms)
```
{cluster="aws-uswest2-prod-a", namespace="ingress-nginx", container="controller"}
|~ "/sofi/update"
| pattern `<_> <_> <_> [<_>] "<_> <_> <_>" <_> <_> <_> <_> <_> [<_>] [] <_> <_> <upstream_latency> <_> <_>`
|~ " 0\\.(1[0-9]{2,}|[2-9][0-9]{2,})"

``` -->

`> 4ms (0.004s)`
```
{cluster="aws-uswest2-prod-a",namespace="ingress-nginx",pod=~".*",stream=~"stdout|stderr",container="controller"}
|~ "/sofi/update "
| pattern "<_> <_> <_> [<_>] \"<_> <_> <_>\" <_> <_> <_> <_> <_> <_> <_> <_> <_> <_> <request_time> <_> <_>"
|~ " [0-9]+ (0\\.00[5-9]|0\\.0[1-9][0-9]*|0\\.[1-9][0-9]*) 200 "

```

#### latency 

alert:
```
```
process:
```
@PI-Sender sent Opsgenie alerts to on-call teams about a high response time issue for the /sofi/update endpoint, which @Caiwei Li and @Yang Zhou investigated. They found no issues in the recent access logs, so @Jianglin Guo and @Rui Shao looked into the ingress controller and potential latency between Nginx and the backend pod.

Less detail
@PI-Sender sent Opsgenie alerts about a high response time issue for the /sofi/update endpoint [1], [2]
@Yang Zhou did not find any update API response time > 500ms in recent 30 mins in access log [3]
@Jianglin Guo suggested the latency might be between Nginx and the backend pod [4]
@Rui Shao was asked to check the ingress controller log [5]
@Rui Shao shared a URL for the ingress controller log [6]
```
1. client åˆ° apisix çš„é—®é¢˜ï¼Ÿå‰ç«¯å…¬ç½‘çš„ç½‘ç»œæŠ–åŠ¨
  - è¿™ä¸ªå…ˆä¸ç®¡
2. apisix çš„é—®é¢˜ï¼Ÿ
  ![](./pic/apisix-metrics.png)
3. ingress nginx çš„é—®é¢˜ï¼Ÿ
  - ingress nginx æœ¬èº« `rtime_client`
  - fp æœ¬èº« `upstream_response_time`
4. fp çš„é—®é¢˜ï¼Ÿ
  - åç«¯ db çš„é—®é¢˜ï¼Ÿ
    - TODO charts çœ‹ä¸€ä¸‹ fp åç«¯ä¾èµ–äº†å“ªäº›ï¼Ÿ


#### 502 erorr code: 
```
Alertmanager :robot_face: reported a high-priority alert about a K8s cluster in the aws-uswest2-prod-b environment returning HTTP 502 errors for the sofi client on the /update request URL, with the upstream prod-fp-8080 service as the source. @Caiwei Li, @Rui Shao, @Jianglin Guo, and @Kelly He investigated the issue, finding that the 502 errors were occurring daily but not visible in the FP logs as they were being returned directly by Tomcat.

Less detail
@Caiwei Li noted that there were a few 502 errors [1]
@Jianglin Guo confirmed the 502 errors were coming from the FP service [2]
@Caiwei Li questioned if the update API was still calling fp-async instead of the FP service as expected [3]
@Jianglin Guo indicated the 502 errors seemed to be a recurring issue [4]
@Jianglin Guo suggested checking the ingress logs to investigate the 502 errors [5]
```
- metrics: sla dashboard 
- nginx log
  - why fp log not show? The Fp log will not find the 502 status log because it is directly returned by tomcat level 

å‰é¢çš„ 200 æ˜¯ ingress è¿”å›ç»™ client çš„æœ€ç»ˆçŠ¶æ€ç 
åé¢çš„ 200 æ˜¯ ingress ä» upstream æ”¶åˆ°çš„çŠ¶æ€ç 

```
{cluster="aws-uswest2-prod-b",namespace="ingress-nginx",pod=~".*",stream=~"stdout|stderr",container="controller"} |~ "1.1\" 502"
```

### apisix log
https://grafana-mgt.dv-api.com/d/0lpCu9kHk/apisix-logging?orgId=1&from=now-1h&to=now&var-cluster=aws-uswest2-prod&var-client=sofi&var-search=

```
å­—æ®µ	ç¤ºä¾‹	å«ä¹‰
client_ip	52.10.42.230	çœŸå®æ¥è®¿ IP
ident	-	HTTP auth ç”¨æˆ·
user	-	HTTP auth ç”¨æˆ·
timestamp	[28/Nov/2025...]	æ—¥å¿—æ—¶é—´
host	gateway-uswest2-prod.dv-api.com	è¯·æ±‚åŸŸå
method	POST	HTTP æ–¹æ³•
uri	/sofi/update	è·¯ç”±è·¯å¾„
status_code	200	æœ€ç»ˆè¿”å›ç»™ client çš„ code
body_bytes_sent	5	body å¤§å°
request_time	0.002	APISIX æ€»è€—æ—¶ï¼ˆåŒ…å« upstreamï¼‰
referer	"-"	HTTP Referer
user_agent	ReactorNetty	å®¢æˆ·ç«¯ UA
upstream_addr	172.31.35.120:443	APISIX ä»£ç†ç›®æ ‡
upstream_status	200	upstream è¿”å›çš„ code
upstream_response_time	0.003	upstream çš„å¤„ç†æ—¶é—´
full_url	https://sofi-apisix
...	åŸå§‹ URL

å­—æ®µ	å€¼	å«ä¹‰
request_time	0.002	APISIX æ•´ä½“å¤„ç†æ—¶é—´ï¼ˆä» receive åˆ° sendï¼‰
upstream_response_time	0.003	upstream æœåŠ¡å¤„ç†æ—¶é—´
```
`> 50ms (0.05)`
```
{external_cluster="external_apisix", cluster=~"aws-uswest2-prod"}
| pattern "<client_ip> <ident> <user> [<time_local>] <host> \"<method> <uri> <protocol>\" <status> <body_bytes_sent> <request_time> \"<referer>\" \"<user_agent>\" <upstream_addr> <upstream_status> <upstream_time> \"<full_url>\""
|~ " [0-9]+ (0\\.[0-9]{2,}|[1-9]\\.[0-9]+) \""

```
### sla
https://grafana-mgt.dv-api.com/d/p1KqfRAMk/sla-batch-and-realtime?orgId=1&var-PromDs=default&var-client=affirm&var-sandbox_client=airasia&var-pipeline=prod.realtime.rtserver.awsuseast1&var-Batch_Pipeline=prod.awsuseast1
### multiple cluster
https://grafana-mgt.dv-api.com/d/X2qhqpjSk/multi-cluster-traffic-distribution?orgId=1

### loki fp service log
**FP æœåŠ¡æ—¥å¿—æŸ¥è¯¢**ï¼ˆæ’æŸ¥ä¸šåŠ¡é€»è¾‘é—®é¢˜ï¼‰:
```
https://grafana-mgt.dv-api.com/explore?left=%7B%22datasource%22:%22Loki%22,%22queries%22:%5B%7B%22datasource%22:%7B%22type%22:%22loki%22,%22uid%22:%22M2q8i3Q7z%22%7D,%22expr%22:%22%7Bcluster%3D%5C%22aws-useast1-prod-a%5C%22,namespace%3D%5C%22prod%5C%22,pod%3D~%5C%22fp-deployment-.*%5C%22,stream%3D~%5C%22stdout%7Cstderr%5C%22,container%3D%5C%22fp%5C%22%7D%22%7D%5D%7D&orgId=1
```

### dashboardé¢æ¿é€ŸæŸ¥

**ä¸»è¦Dashboardé“¾æ¥**:
- **E2E Dashboard**: [SLA Batch and Realtime](https://grafana-mgt.dv-api.com/d/p1KqfRAMk/sla-batch-and-realtime) (21ä¸ªé¢æ¿)
- **E2E for APISIX Dashboard**: [Multi-Cluster Traffic Distribution](https://grafana-mgt.dv-api.com/d/X2qhqpjSk/multi-cluster-traffic-distribution) (11ä¸ªé¢æ¿)

**è¯¦ç»†é¢æ¿åˆ—è¡¨**: è¯·å‚è€ƒ [ğŸ› ï¸ æ’æŸ¥å·¥å…·é€ŸæŸ¥è¡¨ - Grafana Dashboards](#1-grafana-dashboards) ç« èŠ‚ã€‚

impova: 
`curl -I https://admin-sandbox.datavisor.com -H "User-Agent: Mozilla/5.0" -v`
## ğŸ—ï¸ å®Œæ•´è¯·æ±‚é“¾è·¯æ¶æ„ï¼ˆåŒ…å« APISIXï¼‰

### æ¶æ„ A: ç»è¿‡ APISIX çš„è¯·æ±‚è·¯å¾„

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯<br/>(Client)
    participant APISIX as API Gateway<br/>(APISIX)
    participant Ingress as Ingress Controller<br/>(Nginx)
    participant FP as Feature Platform<br/>(FP Pod)
    
    Note over Client,FP: ğŸ“Š å®Œæ•´çš„ E2E è¯·æ±‚æµç¨‹ (with APISIX)
    
    Client->>APISIX: â‘  HTTP Request
    Note right of Client: å¤–éƒ¨ç½‘ç»œå»¶è¿Ÿ<br/>(External Network)
    
    APISIX->>APISIX: â‘¡ APIè·¯ç”±<br/>è®¤è¯/é™æµ
    Note right of APISIX: APISIX å¤„ç†æ—¶é—´<br/>(API Gateway Processing)
    
    APISIX->>Ingress: â‘¢ Forward to Ingress
    Note right of APISIX: å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ<br/>(Internal Network)
    
    Ingress->>Ingress: â‘£ è·¯ç”±è§£æ<br/>è´Ÿè½½å‡è¡¡
    Note right of Ingress: Ingress å¤„ç†æ—¶é—´<br/>(Ingress Processing)
    
    Ingress->>FP: â‘¤ Forward to Upstream
    Note right of Ingress: å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ<br/>(Internal Network)
    
    FP->>FP: â‘¥ ä¸šåŠ¡å¤„ç†<br/>ç‰¹å¾è®¡ç®—
    Note right of FP: Upstream å¤„ç†æ—¶é—´<br/>(upstream_response_time)
    
    FP-->>Ingress: â‘¦ Response
    Note left of FP: å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ
    
    Ingress->>Ingress: â‘§ å“åº”å¤„ç†
    Note left of Ingress: Ingress å¤„ç†
    
    Ingress-->>APISIX: â‘¨ Response
    Note left of Ingress: å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ
    
    APISIX->>APISIX: â‘© å“åº”å¤„ç†<br/>æ—¥å¿—è®°å½•
    Note left of APISIX: APISIX å¤„ç†
    
    APISIX-->>Client: â‘ª HTTP Response
    Note left of APISIX: å¤–éƒ¨ç½‘ç»œå»¶è¿Ÿ
    
    rect rgb(180, 200, 255)
        Note over Client,FP: ğŸ• APISIX Total Response Time<br/>ä»å®¢æˆ·ç«¯åˆ° APISIX å†åˆ° FP çš„å®Œæ•´æ—¶é—´<br/>(E2E for APISIX é¢æ¿æµ‹é‡)
    end
    
    rect rgb(200, 220, 255)
        Note over APISIX,FP: ğŸ•‘ Ingress Total Response Time (request_time)<br/>ä» Ingress æ¥æ”¶åˆ°è¿”å›çš„æ—¶é—´<br/>(E2E é¢æ¿ 1/2 æµ‹é‡)
    end
    
    rect rgb(255, 220, 200)
        Note over FP: ğŸ•’ Upstream Response Time<br/>(upstream_response_time)<br/>FP Pod å®é™…å¤„ç†æ—¶é—´<br/>(E2E é¢æ¿ 3 æµ‹é‡)
    end
    
    rect rgb(220, 255, 220)
        Note over APISIX,Ingress: ğŸ•“ Ingress Waiting Latency<br/>(request_time - upstream_response_time)<br/>ç½‘ç»œ + Ingress å¤„ç†<br/>(E2E é¢æ¿ 4 æµ‹é‡)
    end
```

### æ¶æ„ B: ç›´è¿ Ingress çš„è¯·æ±‚è·¯å¾„ï¼ˆä¸ç»è¿‡ APISIXï¼‰

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯<br/>(Client)
    participant Ingress as Ingress Controller<br/>(Nginx)
    participant FP as Feature Platform<br/>(FP Pod)
    
    Note over Client,FP: ğŸ“Š å®Œæ•´çš„ E2E è¯·æ±‚æµç¨‹ (without APISIX)
    
    Client->>Ingress: â‘  HTTP Request
    Note right of Client: ç½‘ç»œå»¶è¿Ÿ<br/>(Network Latency)
    
    Ingress->>Ingress: â‘¡ è·¯ç”±è§£æ<br/>è´Ÿè½½å‡è¡¡
    Note right of Ingress: Ingress å¤„ç†æ—¶é—´<br/>(Ingress Processing)
    
    Ingress->>FP: â‘¢ Forward to Upstream
    Note right of Ingress: å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ<br/>(Internal Network)
    
    FP->>FP: â‘£ ä¸šåŠ¡å¤„ç†<br/>ç‰¹å¾è®¡ç®—
    Note right of FP: Upstream å¤„ç†æ—¶é—´<br/>(upstream_response_time)
    
    FP-->>Ingress: â‘¤ Response
    Note left of FP: å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ<br/>(Internal Network)
    
    Ingress->>Ingress: â‘¥ å“åº”å¤„ç†
    Note left of Ingress: Ingress å¤„ç†æ—¶é—´<br/>(Ingress Processing)
    
    Ingress-->>Client: â‘¦ HTTP Response
    Note left of Ingress: ç½‘ç»œå»¶è¿Ÿ<br/>(Network Latency)
    
    rect rgb(200, 220, 255)
        Note over Client,FP: ğŸ• Total Response Time (request_time)<br/>ä»å®¢æˆ·ç«¯å‘èµ·åˆ°æ”¶åˆ°å“åº”çš„æ€»æ—¶é—´<br/>(E2E é¢æ¿ 1/2 æµ‹é‡)
    end
    
    rect rgb(255, 220, 200)
        Note over FP: ğŸ•‘ Upstream Response Time<br/>(upstream_response_time)<br/>FP Pod å®é™…å¤„ç†æ—¶é—´<br/>(E2E é¢æ¿ 3 æµ‹é‡)
    end
    
    rect rgb(220, 255, 220)
        Note over Client,Ingress: ğŸ•’ Waiting Latency<br/>(request_time - upstream_response_time)<br/>ç½‘ç»œå»¶è¿Ÿ + Ingress å¤„ç†æ—¶é—´<br/>(E2E é¢æ¿ 4 æµ‹é‡)
    end
```

---

## ğŸ”€ APISIX åœ¨æ¶æ„ä¸­çš„ä½ç½®

### APISIX æ˜¯ä»€ä¹ˆï¼Ÿ
**APISIX** æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„ API Gatewayï¼ˆAPI ç½‘å…³ï¼‰ï¼Œä½äºè¯·æ±‚é“¾è·¯çš„**æœ€å‰ç«¯**ã€‚

### å®Œæ•´çš„æ¶æ„å±‚çº§
```
Client (å®¢æˆ·ç«¯)
   â†“
API Gateway Layer (API ç½‘å…³å±‚)
   â”œâ”€ APISIX (API è·¯ç”±ã€è®¤è¯ã€é™æµ)
   â”œâ”€ API Gateway (ç‰ˆæœ¬ç®¡ç†)
   â”œâ”€ ALB (åº”ç”¨è´Ÿè½½å‡è¡¡)
   â””â”€ Imperva (WAF å®‰å…¨é˜²æŠ¤)
   â†“
Ingress Controller Layer (Ingress æ§åˆ¶å™¨å±‚)
   â””â”€ Nginx Ingress (K8s æµé‡å…¥å£)
   â†“
Service Layer (æœåŠ¡å±‚)
   â””â”€ Kubernetes Service (æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡)
   â†“
Pod Layer (åº”ç”¨å±‚)
   â”œâ”€ FP Pod (å•ç§Ÿæˆ·ç‰¹å¾å¹³å°)
   â””â”€ FP-GROUP Pod (å¤šç§Ÿæˆ·æ‰¹å¤„ç†)
```

### APISIX çš„ä¸»è¦åŠŸèƒ½
1. **API è·¯ç”±**: æ ¹æ® URLã€Header ç­‰è§„åˆ™è·¯ç”±è¯·æ±‚
2. **è®¤è¯æˆæƒ**: API Keyã€JWTã€OAuth2 ç­‰è®¤è¯
3. **é™æµç†”æ–­**: Rate Limitingã€Circuit Breaker
4. **åè®®è½¬æ¢**: HTTP/HTTPSã€gRPCã€WebSocket
5. **å¯è§‚æµ‹æ€§**: æ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ª

### ä¸ºä»€ä¹ˆæœ‰ä¸¤ä¸ª E2E Dashboardï¼Ÿ

#### ğŸ“Š E2E Dashboard (21 ä¸ªé¢æ¿)
- **ç›‘æ§å¯¹è±¡**: Ingress Controller â†’ FP Pod
- **èµ·å§‹ç‚¹**: ä» **Nginx Ingress** æ¥æ”¶åˆ°è¯·æ±‚å¼€å§‹
- **é€‚ç”¨åœºæ™¯**: 
  - ç›´è¿ Ingress çš„è¯·æ±‚ï¼ˆä¸ç»è¿‡ APISIXï¼‰
  - ç›‘æ§ Ingress å’Œ FP Pod çš„æ€§èƒ½
  - å¤§éƒ¨åˆ†å®¢æˆ·ç«¯ä½¿ç”¨è¿™ä¸ªè·¯å¾„

#### ğŸš€ E2E for APISIX Dashboard (11 ä¸ªé¢æ¿)
- **ç›‘æ§å¯¹è±¡**: APISIX â†’ Ingress Controller â†’ FP Pod
- **èµ·å§‹ç‚¹**: ä» **APISIX** æ¥æ”¶åˆ°è¯·æ±‚å¼€å§‹
- **é€‚ç”¨åœºæ™¯**:
  - ç»è¿‡ APISIX çš„è¯·æ±‚ï¼ˆéƒ¨åˆ†é«˜çº§å®¢æˆ·ï¼‰
  - ç›‘æ§å®Œæ•´çš„ API Gateway é“¾è·¯
  - éœ€è¦ APISIX æä¾›çš„é¢å¤–åŠŸèƒ½ï¼ˆè®¤è¯ã€é™æµç­‰ï¼‰

### å»¶è¿Ÿå±‚çº§åˆ†è§£ï¼ˆåŒ…å« APISIXï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        APISIX Total Response Time (æœ€å®Œæ•´çš„å»¶è¿Ÿ)                â”‚
â”‚  = APISIX Processing + Ingress Request Time + Network Overhead  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   APISIX     â”‚  â”‚    Ingress Total Response Time           â”‚â”‚
â”‚  â”‚  Processing  â”‚  â”‚  = Waiting Latency + Upstream Response   â”‚â”‚
â”‚  â”‚              â”‚  â”‚                                           â”‚â”‚
â”‚  â”‚ â€¢ API è·¯ç”±   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚  â”‚ â€¢ è®¤è¯é‰´æƒ   â”‚  â”‚  â”‚  Waiting    â”‚  â”‚    Upstream      â”‚  â”‚â”‚
â”‚  â”‚ â€¢ é™æµæ£€æŸ¥   â”‚  â”‚  â”‚  Latency    â”‚  â”‚    Response      â”‚  â”‚â”‚
â”‚  â”‚ â€¢ æ—¥å¿—è®°å½•   â”‚  â”‚  â”‚             â”‚  â”‚                  â”‚  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â€¢ ç½‘ç»œå»¶è¿Ÿ  â”‚  â”‚  â€¢ FP å¤„ç†æ—¶é—´   â”‚  â”‚â”‚
â”‚                    â”‚  â”‚ â€¢ Ingress   â”‚  â”‚  â€¢ ç‰¹å¾è®¡ç®—      â”‚  â”‚â”‚
â”‚                    â”‚  â”‚   å¤„ç†æ—¶é—´  â”‚  â”‚  â€¢ æ•°æ®åº“æŸ¥è¯¢    â”‚  â”‚â”‚
â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### APISIX å¯¹å»¶è¿Ÿçš„å½±å“

#### âœ… æ­£å¸¸æƒ…å†µ
- **APISIX å¤„ç†æ—¶é—´**: 5-20msï¼ˆP95ï¼‰
- **é¢å¤–å»¶è¿Ÿ**: ç›¸æ¯”ç›´è¿ Ingress å¢åŠ  10-30ms
- **ä¼˜åŠ¿**: æä¾›äº†è®¤è¯ã€é™æµã€è·¯ç”±ç­‰ä¼ä¸šçº§åŠŸèƒ½

#### âš ï¸ APISIX å¯èƒ½å¯¼è‡´çš„å»¶è¿Ÿé—®é¢˜

1. **è®¤è¯æ’ä»¶å»¶è¿Ÿ**
   - JWT éªŒè¯: +5-10ms
   - å¤–éƒ¨è®¤è¯æœåŠ¡: +50-200ms
   - OAuth2: +100-500ms

2. **é™æµæ’ä»¶å»¶è¿Ÿ**
   - Redis é™æµ: +2-5ms
   - æœ¬åœ°é™æµ: +1ms

3. **æ—¥å¿—æ’ä»¶å»¶è¿Ÿ**
   - åŒæ­¥æ—¥å¿—: +10-50ms
   - å¼‚æ­¥æ—¥å¿—: +1-2ms

4. **APISIX æ€§èƒ½ç“¶é¢ˆ**
   - CPU ä¸è¶³: +100-1000ms
   - å†…å­˜ä¸è¶³: +100-2000ms
   - ç½‘ç»œæ‹¥å¡: +50-500ms

---

## ğŸ“Š å››ä¸ª Latency é¢æ¿è¯¦è§£ï¼ˆE2E Dashboardï¼‰

### 1ï¸âƒ£ Response Percentiles from Ingress (è¿‘ä¼¼å€¼)
**æµ‹é‡å¯¹è±¡**: ğŸ“ˆ **Total Response Time (request_time)**

```mermaid
graph LR
    A[Client] -->|â‘ è¯·æ±‚| B[Ingress]
    B -->|â‘¡è½¬å‘| C[FP Pod]
    C -->|â‘¢å“åº”| B
    B -->|â‘£è¿”å›| A
    
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style C fill:#e1ffe1
    
    D[æµ‹é‡èŒƒå›´:<br/>request_time] -.->|è¦†ç›–â‘ â‘¡â‘¢â‘£| A
```

**æ•°æ®æº**: Loki recording rules  
**æŒ‡æ ‡**: `record:loki_kubernetes_monitoring_requests_percentage_time_ingress_nginx_P50/P75/P90/P95/P99/P99.9/P100`

**å«ä¹‰**: 
- ä» Ingress æ¥æ”¶è¯·æ±‚åˆ°è¿”å›å“åº”çš„**å®Œæ•´æ—¶é—´**
- åŒ…å«ï¼šç½‘ç»œå»¶è¿Ÿ + Ingress å¤„ç† + Upstream å¤„ç†
- è¿™æ˜¯**å®¢æˆ·ç«¯æ„ŸçŸ¥åˆ°çš„æ€»å»¶è¿Ÿ**

---

### 2ï¸âƒ£ Response Percentiles from Ingress (LogQL)
**æµ‹é‡å¯¹è±¡**: ğŸ“ˆ **Total Response Time (request_time)** - å®æ—¶è®¡ç®—ç‰ˆæœ¬

```mermaid
graph LR
    A[Client] -->|â‘ è¯·æ±‚| B[Ingress]
    B -->|â‘¡è½¬å‘| C[FP Pod]
    C -->|â‘¢å“åº”| B
    B -->|â‘£è¿”å›| A
    
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style C fill:#e1ffe1
    
    D[LogQL å®æ—¶è®¡ç®—:<br/>quantile_over_time] -.->|æå– request_time| B
```

**æ•°æ®æº**: LogQL æŸ¥è¯¢ï¼ˆå®æ—¶ä»æ—¥å¿—è®¡ç®—ï¼‰  
**æŸ¥è¯¢**: 
```logql
quantile_over_time(0.50,
  {namespace="ingress-nginx", client="$client"} 
  | pattern "... <request_time:float> ..."
  | line_format "{{.request_time}}"
[5m])
```

**å«ä¹‰**: 
- ä¸é¢æ¿ 1 ç›¸åŒï¼Œéƒ½æ˜¯æµ‹é‡ **request_time**
- åŒºåˆ«ï¼šè¿™ä¸ªæ˜¯ä»æ—¥å¿—**å®æ—¶è®¡ç®—**ï¼Œé¢æ¿ 1 ä½¿ç”¨**é¢„èšåˆçš„ recording rule**
- æ›´å‡†ç¡®ï¼Œä½†æŸ¥è¯¢æ€§èƒ½è¾ƒä½

---

### 3ï¸âƒ£ Upstream latency graph (Feature Platform)
**æµ‹é‡å¯¹è±¡**: ğŸ¯ **Upstream Response Time (upstream_response_time)**

```mermaid
graph LR
    A[Client] -->|â‘ è¯·æ±‚| B[Ingress]
    B -->|â‘¡è½¬å‘| C[FP Pod]
    C -->|â‘¢å“åº”| B
    B -->|â‘£è¿”å›| A
    
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style C fill:#e1ffe1
    
    D[æµ‹é‡èŒƒå›´:<br/>upstream_response_time] -.->|åªæµ‹é‡ FP Pod å¤„ç†æ—¶é—´| C
```

**æ•°æ®æº**: LogQL ä» Ingress æ—¥å¿—æå–  
**æŸ¥è¯¢**: 
```logql
quantile_over_time(0.50,
  {namespace="ingress-nginx", client="$client"} 
  | pattern "... <upstream_response_time> ..."
  | upstream_response_time != "-"
  | line_format "{{.upstream_response_time}}"
[5m])
```

**å«ä¹‰**: 
- **åªæµ‹é‡ FP Pod çš„å¤„ç†æ—¶é—´**
- ä» FP Pod æ”¶åˆ°è¯·æ±‚åˆ°è¿”å›å“åº”çš„æ—¶é—´
- **ä¸åŒ…å«ç½‘ç»œå»¶è¿Ÿå’Œ Ingress å¤„ç†æ—¶é—´**
- è¿™æ˜¯**ä¸šåŠ¡é€»è¾‘çš„å®é™…å¤„ç†æ—¶é—´**

---

### 4ï¸âƒ£ Waiting Latency between Ingress and Upstream
**æµ‹é‡å¯¹è±¡**: â³ **Waiting Time = request_time - upstream_response_time**

```mermaid
graph LR
    A[Client] -->|â‘ ç½‘ç»œå»¶è¿Ÿ| B[Ingress]
    B -->|â‘¡Ingresså¤„ç†| B2[Ingress Queue]
    B2 -->|â‘¢å†…ç½‘å»¶è¿Ÿ| C[FP Pod]
    C -->|FPå¤„ç†| C
    C -->|â‘£å†…ç½‘å»¶è¿Ÿ| B3[Ingress]
    B3 -->|â‘¤Ingresså¤„ç†| B4[Ingress]
    B4 -->|â‘¥ç½‘ç»œå»¶è¿Ÿ| A2[Client]
    
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style B2 fill:#ffe1e1
    style B3 fill:#ffe1e1
    style B4 fill:#ffe1e1
    style C fill:#e1ffe1
    style A2 fill:#e1f5ff
    
    D[æµ‹é‡èŒƒå›´:<br/>Waiting Latency] -.->|â‘ +â‘¡+â‘¢+â‘£+â‘¤+â‘¥<br/>ä¸åŒ…å« FP å¤„ç†æ—¶é—´| A
```

**è®¡ç®—å…¬å¼**: 
```
Waiting Latency = Total Response Time - Upstream Response Time
                = request_time - upstream_response_time
                
å…¶ä¸­ï¼š
  â€¢ request_time (external_latency): Ingress è§†è§’çš„æ•´ä½“ä»£ç†è€—æ—¶
  â€¢ upstream_response_time (internal_latency): Ingress â†” Upstream è€—æ—¶
```

**é‡è¦è¯´æ˜**: client â†’ ingress ç½‘ç»œå»¶è¿Ÿä¸åŒ…å«åœ¨è¿™ä¸¤ä¸ªé‡ä¸­ã€‚

**å®é™…å«ä¹‰**: 
> ingress å†…éƒ¨ç­‰å¾… / æ’é˜Ÿ / proxy / è°ƒåº¦ / é™æµ ç­‰å¼€é”€

**åŒ…å«å†…å®¹**: 
- å®¢æˆ·ç«¯åˆ° Ingress çš„ç½‘ç»œå»¶è¿Ÿï¼ˆå¾€è¿”ï¼‰
- Ingress è·¯ç”±è§£æã€è´Ÿè½½å‡è¡¡æ—¶é—´
- Ingress åˆ° FP Pod çš„å†…éƒ¨ç½‘ç»œå»¶è¿Ÿï¼ˆå¾€è¿”ï¼‰
- Ingress å†…éƒ¨æ’é˜Ÿã€proxyã€è°ƒåº¦ã€buffer ç­‰å¼€é”€

**âš ï¸ å¸¸è§è¯¯è§£**:
- âŒ ä¸ä¸€å®šæ˜¯"network issue"
- âš ï¸ æ›´å¤šåæ˜  ingress è‡ªèº«å‹åŠ›

**é«˜ Waiting Latency è¯´æ˜**: ç½‘ç»œæˆ– Ingress æœ‰é—®é¢˜ï¼Œéœ€è¦æ’æŸ¥ï¼š
- Ingress Controller æ€§èƒ½ï¼ˆCPU/Memoryï¼‰
- ç½‘ç»œè´¨é‡ï¼ˆå®¢æˆ·ç«¯åˆ° DataVisor çš„ç½‘ç»œè·¯å¾„ï¼‰
- K8s å†…éƒ¨ç½‘ç»œ
- Ingress æ—¥å¿—ä¸­çš„è¿æ¥è¶…æ—¶

---

## ğŸš€ E2E for APISIX çš„ Latency é¢æ¿

### ğŸ“Š Response Percentiles from Apisix (1 ä¸ªé¢æ¿)

**æµ‹é‡å¯¹è±¡**: ğŸ“ˆ **APISIX Total Response Time**

```mermaid
graph LR
    A[Client] -->|â‘ è¯·æ±‚| B[APISIX]
    B -->|â‘¡è®¤è¯/è·¯ç”±| B2[APISIX Processing]
    B2 -->|â‘¢è½¬å‘| C[Ingress]
    C -->|â‘£è½¬å‘| D[FP Pod]
    D -->|â‘¤å“åº”| C
    C -->|â‘¥è¿”å›| B
    B -->|â‘¦è¿”å›| A
    
    style A fill:#e1f5ff
    style B fill:#ffe1ff
    style B2 fill:#ffe1ff
    style C fill:#ffe1e1
    style D fill:#e1ffe1
    
    E[æµ‹é‡èŒƒå›´:<br/>APISIX Total Time] -.->|è¦†ç›–â‘ -â‘¦| A
```

**æ•°æ®æº**: APISIX Prometheus Metrics  
**æŒ‡æ ‡**: `apisix_monitoring_requests_percentage_time_apisix_bucket`  
**è®¡ç®—æ–¹æ³•**: `histogram_quantile(0.95, rate(apisix_monitoring_requests_percentage_time_apisix_bucket[5m]))`

**å«ä¹‰**: 
- ä» APISIX æ¥æ”¶è¯·æ±‚åˆ°è¿”å›å“åº”çš„**å®Œæ•´æ—¶é—´**
- åŒ…å«ï¼šAPISIX å¤„ç† + Ingress å¤„ç† + FP Pod å¤„ç† + æ‰€æœ‰ç½‘ç»œå»¶è¿Ÿ
- è¿™æ˜¯ç»è¿‡ APISIX çš„å®¢æˆ·ç«¯æ„ŸçŸ¥åˆ°çš„**æ€»å»¶è¿Ÿ**

### ğŸ”„ APISIX vs Ingress å»¶è¿Ÿå¯¹æ¯”

| ç›‘æ§è§†è§’ | E2E (Ingress) | E2E for APISIX | å·®å¼‚ |
|---------|---------------|----------------|------|
| **èµ·å§‹ç‚¹** | Ingress Controller | APISIX Gateway | APISIX æ›´å‰ç«¯ |
| **ç›‘æ§èŒƒå›´** | Ingress â†’ FP Pod | APISIX â†’ Ingress â†’ FP Pod | APISIX è·¯å¾„æ›´é•¿ |
| **æ€»å»¶è¿Ÿ** | request_time | APISIX total time | APISIX å¤š 10-30ms |
| **é€‚ç”¨åœºæ™¯** | ç›´è¿ Ingress | ç»è¿‡ API Gateway | ä¸åŒå®¢æˆ·è·¯å¾„ |

### ğŸ” å¦‚ä½•è®¡ç®— APISIX çš„å¤„ç†æ—¶é—´ï¼Ÿ

**è®¡ç®—å…¬å¼**: è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [ğŸ“ æ ¸å¿ƒå»¶è¿Ÿåˆ†è§£å…¬å¼ - å…¬å¼ 3](#å…¬å¼-3-apisix-processing-time-çš„è®¡ç®—) ç« èŠ‚ã€‚

**è®¡ç®—ç¤ºä¾‹**:
```
  APISIX Total Time:   150ms (E2E for APISIX é¢æ¿)
  Ingress Request Time: 120ms (E2E é¢æ¿ 1)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  APISIX Processing:     30ms (å·®å€¼)
```

**ä¼˜åŒ–å»ºè®®**: å¦‚æœ APISIX Processing > 50msï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–ï¼š
- è®¤è¯æ’ä»¶é…ç½®
- é™æµç­–ç•¥
- æ—¥å¿—è®°å½•æ–¹å¼
- APISIX å®ä¾‹èµ„æº

---

## ğŸ“ æ ¸å¿ƒå»¶è¿Ÿåˆ†è§£å…¬å¼

### å…¬å¼ 1: ä¸ç»è¿‡ APISIX çš„è¯·æ±‚

```
Total Response Time (request_time) = Waiting Latency + Upstream Response Time
     (E2E é¢æ¿ 1/2)                      (E2E é¢æ¿ 4)        (E2E é¢æ¿ 3)
```

**å¯è§†åŒ–åˆ†è§£**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Total Response Time (request_time)              â”‚
â”‚  = Waiting Latency + Upstream Response Time             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Waiting Latency      â”‚  â”‚  Upstream Response     â”‚â”‚
â”‚  â”‚                        â”‚  â”‚       Time             â”‚â”‚
â”‚  â”‚ â€¢ å®¢æˆ·ç«¯ç½‘ç»œå»¶è¿Ÿ(å¾€è¿”) â”‚  â”‚  â€¢ FP Pod å¤„ç†æ—¶é—´     â”‚â”‚
â”‚  â”‚ â€¢ Ingress å¤„ç†æ—¶é—´     â”‚  â”‚  â€¢ ç‰¹å¾è®¡ç®—            â”‚â”‚
â”‚  â”‚ â€¢ å†…éƒ¨ç½‘ç»œå»¶è¿Ÿ(å¾€è¿”)   â”‚  â”‚  â€¢ æ•°æ®åº“æŸ¥è¯¢          â”‚â”‚
â”‚  â”‚ â€¢ è´Ÿè½½å‡è¡¡             â”‚  â”‚  â€¢ ä¸šåŠ¡é€»è¾‘            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…¬å¼ 2: ç»è¿‡ APISIX çš„è¯·æ±‚

```
APISIX Total Time = APISIX Processing + Ingress Request Time
(E2E for APISIX)    (å·®å€¼è®¡ç®—)           (E2E é¢æ¿ 1/2)

å®Œæ•´å±•å¼€:
APISIX Total Time = APISIX Processing + Waiting Latency + Upstream Response Time
(E2E for APISIX)    (å·®å€¼è®¡ç®—)            (E2E é¢æ¿ 4)        (E2E é¢æ¿ 3)
```

### å…¬å¼ 3: APISIX Processing Time çš„è®¡ç®—

```
APISIX Processing Time = APISIX Total Time - Ingress Request Time
                       = (E2E for APISIX) - (E2E é¢æ¿ 1/2)

APISIX Processing åŒ…å«:
  â€¢ API è·¯ç”±åŒ¹é…æ—¶é—´
  â€¢ è®¤è¯æˆæƒéªŒè¯æ—¶é—´
  â€¢ é™æµè§„åˆ™æ£€æŸ¥æ—¶é—´
  â€¢ æ’ä»¶æ‰§è¡Œæ—¶é—´
  â€¢ æ—¥å¿—è®°å½•æ—¶é—´
  â€¢ APISIX åˆ° Ingress çš„ç½‘ç»œä¼ è¾“æ—¶é—´
```

---

## ğŸ¯ ä»€ä¹ˆæƒ…å†µçœ‹ä»€ä¹ˆå»¶è¿Ÿï¼Ÿ

### ğŸ†• åœºæ™¯ 0: å…ˆç¡®å®šè¯·æ±‚è·¯å¾„ï¼ˆæ˜¯å¦ç»è¿‡ APISIXï¼‰

**æ­¥éª¤ 1**: ç¡®è®¤å®¢æˆ·ç«¯ä½¿ç”¨çš„å…¥å£
```
ç»è¿‡ APISIX çš„å®¢æˆ·ç«¯ï¼š
  â†’ æŸ¥çœ‹ "E2E for APISIX" Dashboard
  â†’ ä½¿ç”¨ APISIX Total Response Time

ç›´è¿ Ingress çš„å®¢æˆ·ç«¯ï¼š
  â†’ æŸ¥çœ‹ "E2E" Dashboard
  â†’ ä½¿ç”¨ Ingress Total Response Time
```

**æ­¥éª¤ 2**: å¦‚ä½•åˆ¤æ–­è¯·æ±‚æ˜¯å¦ç»è¿‡ APISIXï¼Ÿ
- æŸ¥çœ‹å®¢æˆ·ç«¯é…ç½®çš„ API ç«¯ç‚¹
- æ£€æŸ¥ DNS è§£æç»“æœ
- æŸ¥çœ‹ APISIX QPS é¢æ¿æ˜¯å¦æœ‰è¯¥å®¢æˆ·ç«¯çš„æµé‡
- æ£€æŸ¥è¯·æ±‚ Header ä¸­æ˜¯å¦æœ‰ APISIX ç‰¹å®šæ ‡è¯†

**æ­¥éª¤ 3**: å¦‚æœä¸¤ä¸ª Dashboard éƒ½æœ‰æ•°æ®
```
å¯¹æ¯” APISIX Total Time vs Ingress Request Time:

APISIX Total:  200ms
Ingress Total: 180ms
å·®å€¼:           20ms  â† APISIX å¤„ç†æ—¶é—´

å¦‚æœå·®å€¼ > 50msï¼Œéœ€è¦ä¼˜åŒ– APISIX é…ç½®
```

---

### åœºæ™¯ 1: å®¢æˆ·ç«¯æŠ±æ€¨å“åº”æ…¢ï¼ˆç»è¿‡ APISIXï¼‰

**æ­¥éª¤ 1**: å…ˆçœ‹ **E2E for APISIX** Dashboard çš„ Response Percentiles
- ç¡®è®¤ APISIX Total Time æ˜¯å¦çœŸçš„é«˜

**æ­¥éª¤ 2**: å¯¹æ¯” **E2E for APISIX** vs **E2E Dashboard**
```
APISIX Total Time:  500ms  (E2E for APISIX)
Ingress Request Time: 450ms  (E2E é¢æ¿ 1)
å·®å€¼:                 50ms  â† APISIX å¤„ç†æ—¶é—´

å¦‚æœå·®å€¼å¤§ï¼ˆ>50msï¼‰:
  â†’ ğŸ”§ APISIX å¤„ç†æ…¢
  â†’ æ’æŸ¥: APISIX æ’ä»¶ã€è®¤è¯ã€é™æµã€æ—¥å¿—

å¦‚æœå·®å€¼å°ï¼ˆ<30msï¼‰:
  â†’ ç»§ç»­ç”¨ E2E Dashboard æ’æŸ¥ Ingress/FP Pod
```

**æ­¥éª¤ 3**: ä½¿ç”¨ E2E Dashboard ç»†åˆ†é—®é¢˜
- æŸ¥çœ‹ **Upstream latency** (é¢æ¿ 3)
- æŸ¥çœ‹ **Waiting Latency** (é¢æ¿ 4)
- æŒ‰ä¹‹å‰çš„é€»è¾‘åˆ¤æ–­æ˜¯ä¸šåŠ¡æ…¢è¿˜æ˜¯ç½‘ç»œæ…¢

---

### åœºæ™¯ 1a: å®¢æˆ·ç«¯æŠ±æ€¨å“åº”æ…¢ï¼ˆä¸ç»è¿‡ APISIXï¼‰
**å…ˆçœ‹**: ğŸ“Š **Response Percentiles from Ingress** (é¢æ¿ 1 æˆ– 2)
- è¿™æ˜¯å®¢æˆ·ç«¯æ„ŸçŸ¥åˆ°çš„æ€»å»¶è¿Ÿ
- æŸ¥çœ‹ P95ã€P99 æ˜¯å¦è¶…æ ‡
- **ç›®æ ‡**: ç¡®è®¤é—®é¢˜æ˜¯å¦çœŸå®å­˜åœ¨

---

### åœºæ™¯ 2: ç¡®å®šæ˜¯ç½‘ç»œé—®é¢˜è¿˜æ˜¯ä¸šåŠ¡é€»è¾‘æ…¢
**å¯¹æ¯”**: ğŸ†š **Upstream latency** (é¢æ¿ 3) vs **Total Response Time** (é¢æ¿ 1)

#### æƒ…å†µ A: Upstream latency é«˜ï¼ŒTotal Response Time ä¹Ÿé«˜
```
Total Response Time:  1500ms  âŒ
Upstream Response:    1400ms  âŒ
Waiting Latency:      100ms   âœ…
```
**ç»“è®º**: ğŸ¯ **ä¸šåŠ¡é€»è¾‘æ…¢**ï¼ˆFP Pod å¤„ç†æ…¢ï¼‰
**æ’æŸ¥æ–¹å‘**:
- æ£€æŸ¥ FP Pod CPU/Memory ä½¿ç”¨ç‡
- æŸ¥çœ‹æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
- åˆ†æç‰¹å¾è®¡ç®—ç®—æ³•ä¼˜åŒ–
- æ£€æŸ¥æ˜¯å¦æœ‰å¤–éƒ¨ä¾èµ–è°ƒç”¨æ…¢

---

#### æƒ…å†µ B: Upstream latency æ­£å¸¸ï¼Œä½† Total Response Time é«˜
```
Total Response Time:  1500ms  âŒ
Upstream Response:    200ms   âœ…
Waiting Latency:      1300ms  âŒ
```
**ç»“è®º**: ğŸŒ **ç½‘ç»œæˆ– Ingress é—®é¢˜**
**æ’æŸ¥æ–¹å‘**:
- æŸ¥çœ‹ **Waiting Latency** é¢æ¿ (é¢æ¿ 4)
- æ£€æŸ¥å®¢æˆ·ç«¯åˆ° Ingress çš„ç½‘ç»œè´¨é‡
- æ£€æŸ¥ Ingress Controller æ€§èƒ½ï¼ˆCPU/Memoryï¼‰
- æ£€æŸ¥ Ingress åˆ° FP Pod çš„å†…éƒ¨ç½‘ç»œ
- æŸ¥çœ‹ Ingress æ—¥å¿—æ˜¯å¦æœ‰è¿æ¥è¶…æ—¶

---

### åœºæ™¯ 3: é—´æ­‡æ€§é«˜å»¶è¿Ÿ
**å…ˆçœ‹**: ğŸ“Š **Response Percentiles from Ingress (LogQL)** (é¢æ¿ 2)
- å®æ—¶è®¡ç®—ï¼Œæ›´å‡†ç¡®
- æŸ¥çœ‹ **P99** å’Œ **P99.9** çš„å·®è·
- å¦‚æœ P99.9 >> P99ï¼Œè¯´æ˜æœ‰å°‘é‡è¯·æ±‚ææ…¢

**ç„¶åçœ‹**: â³ **Waiting Latency** (é¢æ¿ 4)
- å¦‚æœ Waiting Latency çš„ P99.9 ç‰¹åˆ«é«˜ï¼Œå¯èƒ½æ˜¯ï¼š
  - ç½‘ç»œæŠ–åŠ¨
  - Ingress è´Ÿè½½å‡è¡¡é—®é¢˜
  - æŸäº› FP Pod å¥åº·æ£€æŸ¥å¤±è´¥å¯¼è‡´è¿æ¥é‡è¯•

---

### åœºæ™¯ 4: ç‰¹å®šå®¢æˆ·ç«¯å»¶è¿Ÿé«˜
**æ­¥éª¤ 1**: æŸ¥çœ‹ **Response Percentiles from Ingress** (é¢æ¿ 1)
- ä½¿ç”¨ `$client` å˜é‡ç­›é€‰ç‰¹å®šå®¢æˆ·ç«¯
- å¯¹æ¯”è¯¥å®¢æˆ·ç«¯ä¸å…¶ä»–å®¢æˆ·ç«¯çš„å»¶è¿Ÿ

**æ­¥éª¤ 2**: æŸ¥çœ‹ **Upstream latency** (é¢æ¿ 3)
- ç¡®å®šæ˜¯å¦è¯¥å®¢æˆ·ç«¯çš„è¯·æ±‚æ›´å¤æ‚ï¼ˆä¸šåŠ¡é€»è¾‘æ…¢ï¼‰

**æ­¥éª¤ 3**: æŸ¥çœ‹ **Waiting Latency** (é¢æ¿ 4)
- å¦‚æœ Waiting Latency ç‰¹åˆ«é«˜ï¼Œå¯èƒ½æ˜¯ï¼š
  - è¯¥å®¢æˆ·ç«¯ç½‘ç»œè´¨é‡å·®ï¼ˆåœ°ç†ä½ç½®è¿œï¼‰
  - è¯¥å®¢æˆ·ç«¯è¢«è·¯ç”±åˆ°æ€§èƒ½è¾ƒå·®çš„ Ingress/FP Pod

---

### åœºæ™¯ 5: æ’æŸ¥ç½‘ç»œé—®é¢˜
**é‡ç‚¹çœ‹**: â³ **Waiting Latency between Ingress and Upstream** (é¢æ¿ 4)

**æ­£å¸¸æƒ…å†µ**:
```
Waiting Latency P50:   50ms  âœ…
Waiting Latency P95:  100ms  âœ…
Waiting Latency P99:  150ms  âœ…
```

**ç½‘ç»œé—®é¢˜**:
```
Waiting Latency P50:  500ms  âš ï¸
Waiting Latency P95: 2000ms  âŒ
Waiting Latency P99: 5000ms  âŒ
```

**æ’æŸ¥æ–¹å‘**:
- å®¢æˆ·ç«¯å’Œ DataVisor ä¹‹é—´çš„ç½‘ç»œè·¯å¾„
- è·¨åŒºåŸŸ/è·¨å›½ç½‘ç»œé—®é¢˜
- Ingress Controller åˆ° FP Pod çš„ K8s ç½‘ç»œæ€§èƒ½
- æ£€æŸ¥æ˜¯å¦æœ‰ç½‘ç»œç­–ç•¥ï¼ˆNetworkPolicyï¼‰é™åˆ¶

---

### åœºæ™¯ 6: ä¼˜åŒ–æ€§èƒ½
**æ­¥éª¤ 1**: æŸ¥çœ‹ **Upstream latency** (é¢æ¿ 3) çš„ **P95/P99**
- å¦‚æœ > 200msï¼Œä¼˜åŒ–ä¸šåŠ¡é€»è¾‘

**æ­¥éª¤ 2**: æŸ¥çœ‹ **Waiting Latency** (é¢æ¿ 4) çš„ **P95/P99**
- å¦‚æœ > 100msï¼Œä¼˜åŒ–ç½‘ç»œ/Ingress

**æ­¥éª¤ 3**: æŸ¥çœ‹ **Total Response Time** (é¢æ¿ 1) çš„æ”¹å–„
- éªŒè¯ä¼˜åŒ–æ•ˆæœ

---

## ğŸ“ˆ ç›‘æ§æŒ‡æ ‡å‚è€ƒå€¼ï¼ˆåŒ…å« APISIXï¼‰

### âœ… æ­£å¸¸æƒ…å†µï¼ˆå‚è€ƒå€¼ï¼‰
| æŒ‡æ ‡ | P50 | P95 | P99 | P99.9 |
|------|-----|-----|-----|-------|
| **APISIX Total Time** | < 120ms | < 330ms | < 550ms | < 1050ms |
| **APISIX Processing** | < 20ms | < 30ms | < 50ms | < 100ms |
| **Total Response Time** | < 100ms | < 300ms | < 500ms | < 1000ms |
| **Upstream Response** | < 50ms | < 150ms | < 300ms | < 500ms |
| **Waiting Latency** | < 50ms | < 100ms | < 200ms | < 500ms |

### âš ï¸ éœ€è¦å…³æ³¨ï¼ˆé»„è‰²è­¦å‘Šï¼‰
| æŒ‡æ ‡ | P50 | P95 | P99 | P99.9 |
|------|-----|-----|-----|-------|
| **APISIX Total Time** | 120-220ms | 330-550ms | 550-1050ms | 1050-2050ms |
| **APISIX Processing** | 20-50ms | 30-100ms | 50-200ms | 100-500ms |
| **Total Response Time** | 100-200ms | 300-500ms | 500-1000ms | 1000-2000ms |
| **Upstream Response** | 50-100ms | 150-300ms | 300-500ms | 500-1000ms |
| **Waiting Latency** | 50-100ms | 100-200ms | 200-500ms | 500-1000ms |

### âŒ ä¸¥é‡é—®é¢˜ï¼ˆçº¢è‰²å‘Šè­¦ï¼‰
| æŒ‡æ ‡ | P50 | P95 | P99 | P99.9 |
|------|-----|-----|-----|-------|
| **APISIX Total Time** | > 220ms | > 550ms | > 1050ms | > 2050ms |
| **APISIX Processing** | > 50ms | > 100ms | > 200ms | > 500ms |
| **Total Response Time** | > 200ms | > 500ms | > 1000ms | > 2000ms |
| **Upstream Response** | > 100ms | > 300ms | > 500ms | > 1000ms |
| **Waiting Latency** | > 100ms | > 200ms | > 500ms | > 1000ms |

### ğŸ“Š APISIX Processing Time çš„åˆç†èŒƒå›´

| APISIX é…ç½® | é¢„æœŸå»¶è¿Ÿ (P95) |
|-------------|----------------|
| **ä»…è·¯ç”±** | 5-10ms |
| **+ æœ¬åœ°è®¤è¯** | 10-20ms |
| **+ Redis é™æµ** | 15-25ms |
| **+ å¤–éƒ¨è®¤è¯** | 50-200ms |
| **+ åŒæ­¥æ—¥å¿—** | 20-50ms |
| **+ å¤šä¸ªæ’ä»¶** | 30-100ms |

**æ³¨æ„**: å¦‚æœ APISIX Processing > 50ms (P95)ï¼Œéœ€è¦æ£€æŸ¥ï¼š
- æ˜¯å¦å¯ç”¨äº†è€—æ—¶çš„å¤–éƒ¨è®¤è¯
- æ—¥å¿—æ’ä»¶æ˜¯å¦ä½¿ç”¨åŒæ­¥æ¨¡å¼
- APISIX å®ä¾‹æ˜¯å¦èµ„æºä¸è¶³
- æ˜¯å¦æœ‰è¿‡å¤šçš„æ’ä»¶é…ç½®

---

## ğŸ› ï¸ å¿«é€Ÿè¯Šæ–­å†³ç­–æ ‘ï¼ˆåŒ…å« APISIXï¼‰

```mermaid
graph TD
    A[å®¢æˆ·ç«¯åé¦ˆå»¶è¿Ÿé«˜] --> B{è¯·æ±‚æ˜¯å¦<br/>ç»è¿‡ APISIX?}
    
    B -->|æ˜¯| C[æŸ¥çœ‹ E2E for APISIX Dashboard]
    B -->|å¦| D[æŸ¥çœ‹ E2E Dashboard]
    
    C --> C1{APISIX Total Time<br/>æ˜¯å¦å¼‚å¸¸?}
    C1 -->|æ­£å¸¸| C2[å®¢æˆ·ç«¯æœ¬åœ°é—®é¢˜]
    C1 -->|å¼‚å¸¸| C3{å¯¹æ¯” Ingress<br/>Request Time}
    
    C3 -->|å·®å€¼å¤§<br/>>50ms| C4[ğŸ”§ APISIX å¤„ç†æ…¢]
    C3 -->|å·®å€¼å°<br/><30ms| D
    
    C4 --> C5[ä¼˜åŒ– APISIX]
    C5 --> C6[æ£€æŸ¥è®¤è¯æ’ä»¶]
    C5 --> C7[æ£€æŸ¥é™æµé…ç½®]
    C5 --> C8[æ£€æŸ¥æ—¥å¿—æ’ä»¶]
    C5 --> C9[æ£€æŸ¥ APISIX èµ„æº]
    
    D --> D1{Total Response Time<br/>æ˜¯å¦å¼‚å¸¸?}
    D1 -->|æ­£å¸¸| D2[å®¢æˆ·ç«¯æœ¬åœ°é—®é¢˜]
    D1 -->|å¼‚å¸¸| D3{Upstream Response<br/>æ˜¯å¦æ­£å¸¸?}
    
    D3 -->|é«˜| E[ğŸ¯ ä¸šåŠ¡é€»è¾‘æ…¢]
    D3 -->|æ­£å¸¸| F{Waiting Latency<br/>æ˜¯å¦é«˜?}
    
    F -->|é«˜| G[ğŸŒ ç½‘ç»œæˆ–Ingressé—®é¢˜]
    F -->|æ­£å¸¸| H[æ•°æ®å¼‚å¸¸,é‡æ–°æ£€æŸ¥]
    
    E --> E1[ä¼˜åŒ– FP Pod æ€§èƒ½]
    E1 --> E2[æ£€æŸ¥ CPU/Memory]
    E1 --> E3[ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢]
    E1 --> E4[ä¼˜åŒ–ç®—æ³•]
    
    G --> G1[æ’æŸ¥ç½‘ç»œé—®é¢˜]
    G1 --> G2[æ£€æŸ¥å®¢æˆ·ç«¯ç½‘ç»œ]
    G1 --> G3[æ£€æŸ¥ Ingress/Nginx]
    G1 --> G4[æ£€æŸ¥å†…éƒ¨ç½‘ç»œ]
    
    G3 --> G31[æŸ¥çœ‹ Nginx error.log]
    G3 --> G32[åˆ†æ upstream timeout]
    G3 --> G33[æ£€æŸ¥åç«¯æœåŠ¡å¥åº·]
    
    style C4 fill:#ffccff
    style E fill:#ffcccc
    style G fill:#ccffcc
    style C5 fill:#ffe6ff
    style C6 fill:#ffe6ff
    style C7 fill:#ffe6ff
    style C8 fill:#ffe6ff
    style C9 fill:#ffe6ff
    style E1 fill:#ffe6cc
    style E2 fill:#ffe6cc
    style E3 fill:#ffe6cc
    style E4 fill:#ffe6cc
    style G1 fill:#e6ffcc
    style G2 fill:#e6ffcc
    style G3 fill:#e6ffcc
    style G4 fill:#e6ffcc
    style G31 fill:#e6ffcc
    style G32 fill:#e6ffcc
    style G33 fill:#e6ffcc
```

---

## ğŸ”¬ é«˜çº§è°ƒè¯•æŠ€å·§

### æŠ€å·§ 1: è®¡ç®—ç½‘ç»œå»¶è¿Ÿå æ¯”
```
Network Percentage = (Waiting Latency / Total Response Time) Ã— 100%

å¦‚æœ > 50%: ä¸»è¦æ˜¯ç½‘ç»œé—®é¢˜
å¦‚æœ < 20%: ä¸»è¦æ˜¯ä¸šåŠ¡é€»è¾‘æ…¢
```

### æŠ€å·§ 2: å¯¹æ¯”ä¸åŒæ—¶é—´èŒƒå›´çš„å»¶è¿Ÿ
- P50 æ­£å¸¸ä½† P99 é«˜ â†’ é—´æ­‡æ€§é—®é¢˜ï¼ˆå¯èƒ½æ˜¯æŸäº›è¯·æ±‚æˆ–æŸäº› Podï¼‰
- P50/P95/P99 éƒ½é«˜ â†’ ç³»ç»Ÿæ€§é—®é¢˜ï¼ˆæ•´ä½“æ€§èƒ½ä¸‹é™ï¼‰

### æŠ€å·§ 3: å…³è” QPS å’Œ Latency
- å¦‚æœ QPS ä¸Šå‡æ—¶ Latency ä¹Ÿä¸Šå‡ â†’ ç³»ç»Ÿè´Ÿè½½é—®é¢˜
- å¦‚æœ QPS æ­£å¸¸ä½† Latency é«˜ â†’ å…¶ä»–åŸå› ï¼ˆç½‘ç»œ/æ•°æ®åº“/ç®—æ³•ï¼‰

### æŠ€å·§ 4: ä½¿ç”¨ Non-200 QPS é¢æ¿
- å¦‚æœ 5xx é”™è¯¯å¤š â†’ FP Pod é—®é¢˜
- å¦‚æœ 4xx é”™è¯¯å¤š â†’ å®¢æˆ·ç«¯è¯·æ±‚é—®é¢˜
- å¦‚æœ 499 é”™è¯¯å¤š â†’ å®¢æˆ·ç«¯è¶…æ—¶æ–­å¼€ï¼ˆå¯èƒ½æ˜¯å»¶è¿Ÿå¤ªé«˜å¯¼è‡´ï¼‰

---

## ğŸ“ å®æˆ˜æ¡ˆä¾‹åˆ†æ

### æ¡ˆä¾‹ 1: Nginx Upstream Timeout

```mermaid
flowchart TD
    A[å‘Šè­¦: Latency 762ms<br/>Error Rate 83%] --> B[å¤šé›†ç¾¤å¯¹æ¯”]
    B --> C{èŒƒå›´åˆ¤æ–­}
    C -->|å…¨å±€| D[ç½‘ç»œ/Ingresså±‚]
    C -->|ç‰¹å®šå®¢æˆ·| E[SLAåˆ†è§£]
    E --> F[ä¸Šæ¸¸: Clientâ†’Ingressâ†’FP]
    E --> G[FPè‡ªèº«å¤„ç†]
    E --> H[ä¸‹æ¸¸: FPâ†’RT Controller]
    H --> I[DNSè§£æ]
    I --> J[SSHåˆ°NginxèŠ‚ç‚¹]
    J --> K[æ£€æŸ¥æ—¥å¿—]
    K --> L[upstream timed out]
    L --> M[æ£€æŸ¥åç«¯Pod]
    style A fill:#ffcccc
    style L fill:#ffffcc
```

**å…³é”®å‘ç°**:
- FPæ—¥å¿—: `ResourceAccessException` â†’ RT Controlleræ— å“åº”
- DNS: `rt-internal-useast1.dv-api.com` â†’ `172.30.106.23`
- Nginx error.log: `upstream timed out (110)` â†’ åç«¯`172.30.4.159:25104`è¶…æ—¶
- æ ¹å› : RT Controllerå“åº”è¶…æ—¶ï¼ŒNginxç­‰å¾…åç«¯è¶…æ—¶

**Nginxæ—¥å¿—åˆ†æ**: è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [Nginx request_time è¯´æ˜](#nginx-request_time-ç»å¯¹æ—¶é—´) ç« èŠ‚ã€‚

**å…³é”®å­—æ®µ**:
- å­—æ®µ13: `request_time` - æ€»å»¶è¿Ÿ
- å­—æ®µ18: `upstream_response_time` - åç«¯å»¶è¿Ÿ

**å¯¹æ¯”åˆ†æç¤ºä¾‹**:
| request_time | upstream_time | é—®é¢˜å®šä½ |
|-------------|---------------|----------|
| 0.200 | 0.180 | åç«¯æ…¢ |
| 0.200 | 0.010 | Nginx/ç½‘ç»œæ…¢ |

---

### æ¡ˆä¾‹ 2: æ ‡å‡†Debugæµç¨‹

**Step 1: å‘Šè­¦å®šä½**
- ç¡®è®¤å‘Šè­¦æ¥æºï¼ˆSLA/Prometheusè§„åˆ™ï¼‰
- åˆ¤æ–­æ˜¯ingress latencyè¿˜æ˜¯downstream latency

**Step 2: FPæœåŠ¡ç«¯æ’æŸ¥**
```bash
# æœç´¢å¼‚å¸¸
grep "ResourceAccessException\|NoHttpResponseException" fp.log
# ç»“åˆtrace IDå®šä½å®¢æˆ·/æ¥å£
```

**Step 3: SLA Dashboardåˆ†è§£**
- å¯¹æ¯”FPå¤„ç†æ—¶é—´ vs ä¸‹æ¸¸è°ƒç”¨æ—¶é—´
- å¤šé›†ç¾¤åŒå®¢æˆ·æŒ‡æ ‡å¯¹æ¯”

**Step 4: RT Controller/Nginxæ’æŸ¥**
```bash
# DNSè§£æ
nslookup rt-internal-useast1.dv-api.com
# è¿æ¥æµ‹è¯•
curl -vk https://rt-internal-useast1.dv-api.com/health
# SSHåˆ°NginxèŠ‚ç‚¹
ssh -i /path/to/pem ubuntu@172.30.106.23
# é…ç½®æ£€æŸ¥
nginx -t
# é”™è¯¯æ—¥å¿—
grep -i "timed\|upstream" /mnt/log/nginx/error.log | tail -100
# è®¿é—®æ—¥å¿—ï¼ˆupstream_response_timeï¼‰
tail -f /mnt/log/nginx/access.log | awk '{print $18}'
```

**Step 5: åç«¯åº”ç”¨å¥åº·**
```bash
kubectl get pod -n <ns>
kubectl logs <pod>
# æ£€æŸ¥OOM/æŠ¥é”™/è´Ÿè½½
```

**Step 6: é“¾è·¯å¯¹æ¯”**
- ç”»å‡ºFPâ†’RT Controllerâ†’Upstreamé“¾è·¯
- æ ‡æ³¨æ¯å±‚QPS/Latencyæ‰¾ç“¶é¢ˆ

---

## ğŸ“š æ€»ç»“

### E2E Dashboard (ä¸ç»è¿‡ APISIX)

| é¢æ¿ | æµ‹é‡å¯¹è±¡ | ä¸»è¦ç”¨é€” | å…³é”®åœºæ™¯ |
|------|----------|----------|----------|
| **1. Response Percentiles (Recording Rule)** | Total Response Time | å¿«é€ŸæŸ¥çœ‹æ€»å»¶è¿Ÿ | æ—¥å¸¸ç›‘æ§ |
| **2. Response Percentiles (LogQL)** | Total Response Time | å®æ—¶ç²¾ç¡®å»¶è¿Ÿ | é—®é¢˜æ’æŸ¥ |
| **3. Upstream latency** | FP Pod å¤„ç†æ—¶é—´ | å®šä½ä¸šåŠ¡é€»è¾‘æ€§èƒ½ | ä¼˜åŒ–ä¸šåŠ¡ä»£ç  |
| **4. Waiting Latency** | ç½‘ç»œ+Ingresså»¶è¿Ÿ | å®šä½ç½‘ç»œ/Ingressé—®é¢˜ | æ’æŸ¥ç½‘ç»œæ•…éšœ |

### E2E for APISIX Dashboard (ç»è¿‡ APISIX)

| é¢æ¿ | æµ‹é‡å¯¹è±¡ | ä¸»è¦ç”¨é€” | å…³é”®åœºæ™¯ |
|------|----------|----------|----------|
| **Response Percentiles from Apisix** | APISIX Total Time | å®Œæ•´ API Gateway å»¶è¿Ÿ | APISIX å®¢æˆ·ç«¯ç›‘æ§ |

### æ ¸å¿ƒå…¬å¼

è¯¦ç»†å…¬å¼è¯´æ˜è¯·å‚è€ƒ [ğŸ“ æ ¸å¿ƒå»¶è¿Ÿåˆ†è§£å…¬å¼](#-æ ¸å¿ƒå»¶è¿Ÿåˆ†è§£å…¬å¼) ç« èŠ‚ã€‚

---

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

### 1. ç›‘æ§ç­–ç•¥

#### ç»è¿‡ APISIX çš„å®¢æˆ·ç«¯
```
ä¼˜å…ˆçº§ 1: ç›‘æ§ APISIX Total Time (E2E for APISIX)
ä¼˜å…ˆçº§ 2: å¯¹æ¯” Ingress Total Time è®¡ç®— APISIX Processing
ä¼˜å…ˆçº§ 3: ä½¿ç”¨ E2E Dashboard ç»†åˆ† Ingress/FP Pod é—®é¢˜
```

#### ç›´è¿ Ingress çš„å®¢æˆ·ç«¯
```
ä¼˜å…ˆçº§ 1: ç›‘æ§ Total Response Time (E2E é¢æ¿ 1/2)
ä¼˜å…ˆçº§ 2: å¯¹æ¯” Upstream vs Waiting Latency
ä¼˜å…ˆçº§ 3: å®šä½é—®é¢˜åœ¨ä¸šåŠ¡é€»è¾‘è¿˜æ˜¯ç½‘ç»œå±‚
```

### 2. å‘Šè­¦é…ç½®å»ºè®®

```yaml
# APISIX å®¢æˆ·ç«¯å‘Šè­¦
- alert: APISIX_High_Latency
  expr: histogram_quantile(0.95, apisix_monitoring_requests_percentage_time_apisix_bucket) > 500
  duration: 5m
  severity: warning
  
- alert: APISIX_Processing_Slow
  expr: (apisix_total_time - ingress_request_time) > 50
  duration: 5m
  severity: warning

# Ingress å®¢æˆ·ç«¯å‘Šè­¦
- alert: Ingress_High_Latency
  expr: histogram_quantile(0.95, ingress_request_time_bucket) > 500
  duration: 5m
  severity: warning

# é€šç”¨å‘Šè­¦
- alert: Upstream_Processing_Slow
  expr: histogram_quantile(0.95, upstream_response_time_bucket) > 300
  duration: 5m
  severity: warning
  
- alert: Network_Latency_High
  expr: histogram_quantile(0.95, waiting_latency_bucket) > 200
  duration: 5m
  severity: warning
```

### 3. æ€§èƒ½ä¼˜åŒ–ä¼˜å…ˆçº§

#### åœºæ™¯ A: APISIX Processing é«˜ (> 50ms)
```
ä¼˜å…ˆçº§ 1: å°†åŒæ­¥æ—¥å¿—æ”¹ä¸ºå¼‚æ­¥æ—¥å¿—
ä¼˜å…ˆçº§ 2: ä½¿ç”¨æœ¬åœ°é™æµæ›¿ä»£ Redis é™æµ
ä¼˜å…ˆçº§ 3: ä¼˜åŒ–è®¤è¯æ’ä»¶ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
ä¼˜å…ˆçº§ 4: å¢åŠ  APISIX å®ä¾‹èµ„æº
```

#### åœºæ™¯ B: Upstream Response é«˜ (> 300ms)
```
ä¼˜å…ˆçº§ 1: ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
ä¼˜å…ˆçº§ 2: ä¼˜åŒ–ç®—æ³•å’Œä¸šåŠ¡é€»è¾‘
ä¼˜å…ˆçº§ 3: å¢åŠ  FP Pod èµ„æº
ä¼˜å…ˆçº§ 4: å¯ç”¨åº”ç”¨ç¼“å­˜
```

#### åœºæ™¯ C: Waiting Latency é«˜ (> 200ms)
```
ä¼˜å…ˆçº§ 1: æ£€æŸ¥å®¢æˆ·ç«¯åˆ° DataVisor çš„ç½‘ç»œè·¯å¾„
ä¼˜å…ˆçº§ 2: ä¼˜åŒ– Ingress Controller æ€§èƒ½
ä¼˜å…ˆçº§ 3: æ£€æŸ¥ K8s å†…éƒ¨ç½‘ç»œ
ä¼˜å…ˆçº§ 4: è€ƒè™‘ä½¿ç”¨ CDN æˆ–è¾¹ç¼˜èŠ‚ç‚¹
```

### 4. å¿«é€Ÿæ’æŸ¥ Checklist

```
â–¡ ç¡®è®¤è¯·æ±‚è·¯å¾„ï¼ˆæ˜¯å¦ç»è¿‡ APISIXï¼‰
â–¡ æŸ¥çœ‹å¯¹åº”çš„ E2E Dashboard
â–¡ è®°å½• Total Response Time çš„ P50/P95/P99
â–¡ å¦‚æœç»è¿‡ APISIXï¼Œè®¡ç®— APISIX Processing Time
â–¡ å¯¹æ¯” Upstream Response Time å’Œ Waiting Latency
â–¡ ç¡®å®šé—®é¢˜ç±»å‹ï¼š
  - APISIX æ…¢: ä¼˜åŒ– API Gateway é…ç½®
  - Upstream æ…¢: ä¼˜åŒ–ä¸šåŠ¡é€»è¾‘
  - Waiting æ…¢: ä¼˜åŒ–ç½‘ç»œ/Ingress
â–¡ æ ¹æ®é—®é¢˜ç±»å‹æ‰§è¡Œç›¸åº”çš„ä¼˜åŒ–æªæ–½
â–¡ éªŒè¯ä¼˜åŒ–æ•ˆæœå¹¶æŒç»­ç›‘æ§
```

---

## ğŸ› ï¸ æ’æŸ¥å·¥å…·é€ŸæŸ¥è¡¨

### 1. Grafana Dashboards
```
# E2E Dashboard (Ingress)
https://grafana-mgt.dv-api.com/d/p1KqfRAMk/sla-batch-and-realtime

# E2E for APISIX Dashboard
https://grafana-mgt.dv-api.com/d/X2qhqpjSk/multi-cluster-traffic-distribution

# Loki FP æœåŠ¡æ—¥å¿—
https://grafana-mgt.dv-api.com/explore?left=%7B%22datasource%22:%22Loki%22...

# Nginx Ingress æ—¥å¿—
{cluster="aws-uswest2-prod-a",namespace="ingress-nginx",container="controller"}
|~ "/sofi/update"

# APISIX æ—¥å¿—
{external_cluster="external_apisix", cluster=~"aws-uswest2-prod"}
```

### 2. Nginx è¯Šæ–­
```bash
# === çŠ¶æ€æ£€æŸ¥ ===
systemctl status nginx
ss -tulnp | grep nginx
ps -ef | grep nginx

# === æ—¥å¿—åˆ†æ ===
# é”™è¯¯æ—¥å¿—
tail -f /var/log/nginx/error.log
journalctl -fu nginx

# è¶…æ—¶é—®é¢˜
grep -i "timed\|upstream" /mnt/log/nginx/error.log | tail -100

# è®¿é—®æ—¥å¿—ï¼ˆå»¶è¿Ÿåˆ†æï¼‰
tail -f /mnt/log/nginx/access.log | awk '{print $18}'  # upstream_response_time
tail -f /mnt/log/nginx/access.log | awk '{print $13}'  # request_time

# === é…ç½®ç®¡ç† ===
# æµ‹è¯•é…ç½®
nginx -t
# æŸ¥çœ‹å®Œæ•´é…ç½®
nginx -T | less
# é‡è½½é…ç½®
nginx -t && systemctl reload nginx

# === ç«¯å£å ç”¨ ===
ss -tulnp | grep ':80\|:443'
lsof -i :80

# === å¸¸è§é—®é¢˜ ===
# 502 Bad Gateway
tail -f /var/log/nginx/error.log | grep upstream

# 504 Gateway Timeout
# è°ƒæ•´é…ç½®: proxy_read_timeout, proxy_connect_timeout
```

### 3. ç½‘ç»œè¯Šæ–­
```bash
# DNS è§£æ
nslookup rt-internal-useast1.dv-api.com

# è¿æ¥æµ‹è¯•
curl -vk https://rt-internal-useast1.dv-api.com/health
openssl s_client -connect rt-internal-useast1.dv-api.com:443

# Pod ç½‘ç»œæµ‹è¯•
kubectl exec -it <pod> -- curl -v http://<service>:8080
```

### 4. K8s è¯Šæ–­
```bash
# Pod çŠ¶æ€
kubectl get pod -n <namespace>
kubectl describe pod <pod> -n <namespace>

# æ—¥å¿—æŸ¥çœ‹
kubectl logs <pod> -n <namespace> --tail=100 -f

# Service æ£€æŸ¥
kubectl get svc -n <namespace>
kubectl get endpoints <service> -n <namespace>

# Ingress æ£€æŸ¥
kubectl get ingress -n <namespace>
kubectl describe ingress <ingress> -n <namespace>
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- **ç³»ç»Ÿæ¶æ„æ–‡æ¡£**: `blogs/architecture-request-routing-flow.md`
- **E2E Dashboard åˆ†æ**: `grafana_e2e_summary.md`
- **Nginx æ’æŸ¥å®æˆ˜**: `blogs/monitoring-latency_troubleshooting_guide-with-nginx.md`
- **APISIX é…ç½®æ–‡æ¡£**: (è¯·è¡¥å……é“¾æ¥)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v3.1 (é‡æ„ç‰ˆæœ¬ - å»é™¤é‡å¤å†…å®¹ï¼Œä¼˜åŒ–ç»“æ„)  
**æœ€åæ›´æ–°**: 2025-12-23  
**ä½œè€…**: Grafana E2E Dashboard Analysis  

**é‡æ„ä¼˜åŒ–**:
- âœ… **å»é™¤é‡å¤å†…å®¹**: æ•´åˆäº†4å¤„é‡å¤çš„å»¶è¿Ÿå…¬å¼ã€2å¤„Waiting Latencyè¯´æ˜ã€2å¤„Nginxæ—¥å¿—æ ¼å¼è¯´æ˜
- âœ… **ä¼˜åŒ–æ–‡æ¡£ç»“æ„**: ç»Ÿä¸€å…¬å¼åˆ°æ ¸å¿ƒå…¬å¼ç« èŠ‚ï¼Œç®€åŒ–æŒ‡æ ‡å¯¹ç…§è¡¨ï¼Œåˆå¹¶Dashboardé€ŸæŸ¥è¡¨
- âœ… **æ”¹è¿›å¯è¯»æ€§**: ä½¿ç”¨ç« èŠ‚å¼•ç”¨ä»£æ›¿é‡å¤å†…å®¹ï¼Œæé«˜æ–‡æ¡£ç»´æŠ¤æ€§

**æ•´åˆå†…å®¹**:
- âœ… å®Œæ•´çš„è¯·æ±‚é“¾è·¯æ¶æ„ï¼ˆåŒ…å« APISIXï¼‰
- âœ… E2E å’Œ E2E for APISIX Dashboard å¯¹æ¯”
- âœ… 4+1 ä¸ª Latency é¢æ¿è¯¦ç»†åˆ†æ
- âœ… æ ¸å¿ƒå»¶è¿Ÿåˆ†è§£å…¬å¼ï¼ˆç»Ÿä¸€ç‰ˆæœ¬ï¼‰
- âœ… 6+ ä¸ªå®æˆ˜åœºæ™¯æ’æŸ¥æŒ‡å—
- âœ… å¿«é€Ÿè¯Šæ–­å†³ç­–æ ‘ï¼ˆåŒ…å« APISIX å’Œ Nginxï¼‰
- âœ… ç›‘æ§æŒ‡æ ‡å‚è€ƒå€¼
- âœ… æœ€ä½³å®è·µå’Œä¼˜åŒ–å»ºè®®
- âœ… **2ä¸ªå®æˆ˜æ¡ˆä¾‹**ï¼ˆNginx Upstream Timeout + æ ‡å‡†Debugæµç¨‹ï¼‰
- âœ… **Dashboard é¢æ¿é€ŸæŸ¥è¡¨**ï¼ˆåœ¨å·¥å…·é€ŸæŸ¥è¡¨ä¸­ï¼‰
- âœ… **å®Œæ•´æ’æŸ¥å·¥å…·é›†**ï¼ˆGrafana + Nginx + ç½‘ç»œ + K8sï¼‰
- âœ… **Nginx è¯Šæ–­å‘½ä»¤å¤§å…¨**ï¼ˆçŠ¶æ€/æ—¥å¿—/é…ç½®/æ•…éšœï¼‰

**å·²æ•´åˆæ–‡æ¡£**:
- `oncall-fp-latency-issues.md` â†’ å®æˆ˜æ¡ˆä¾‹éƒ¨åˆ†
- `monitoring-grafana_sla_ec2_summary.md` â†’ Dashboard é€ŸæŸ¥è¡¨
- `monitoring-latency_troubleshooting_guide-with-nginx.md` â†’ Nginx æ’æŸ¥éƒ¨åˆ†

